<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    
    <meta name="author" content="YiQi">
    <!-- preconnect -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    
    
    <!--- Seo Part-->
    
    <link rel="canonical" href="http://fengyiqi.github.io/2023/cuda5/"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    
        <meta property="og:type" content="article">
<meta property="og:title" content="CUDA编程05: CUDA流与统一内存">
<meta property="og:url" content="http://fengyiqi.github.io/2023/cuda5/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://yiqiblogimages.oss-cn-hangzhou.aliyuncs.com/cuda/teslak40_sm.png">
<meta property="og:image" content="https://yiqiblogimages.oss-cn-hangzhou.aliyuncs.com/cuda/teslak40_smlimit.png">
<meta property="og:image" content="https://yiqiblogimages.oss-cn-hangzhou.aliyuncs.com/cuda/teslak40_transfer.png">
<meta property="article:published_time" content="2023-01-16T12:49:31.000Z">
<meta property="article:modified_time" content="2023-03-11T21:57:58.985Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="CUDA">
<meta property="article:tag" content="C">
<meta property="article:tag" content="C++">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yiqiblogimages.oss-cn-hangzhou.aliyuncs.com/cuda/teslak40_sm.png">
    
    
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="/images/logo.svg" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/logo.svg">
    <meta name="theme-color" content="#A31F34">
    <link rel="shortcut icon" href="/images/logo.svg">
    <!--- Page Info-->
    
    <title>
        
            CUDA编程05: CUDA流与统一内存 -
        
        YiQi&#39;s Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    
<link rel="stylesheet" href="/assets/fonts.css">

    <!--- Font Part-->
    
    
    
    

    <!--- Inject Part-->
    
    <script id="hexo-configurations">
    let Global = window.Global || {};
    Global.hexo_config = {"hostname":"fengyiqi.github.io","root":"/","language":"zh-CN"};
    Global.theme_config = {"articles":{"style":{"font_size":"18px","line_height":1.5,"image_border_radius":"8px","image_alignment":"center","image_caption":false,"link_icon":true},"word_count":{"enable":true,"count":true,"min2read":true},"author_label":{"enable":true,"auto":false,"list":["管理员"]},"code_block":{"copy":true,"style":"simple","font":{"enable":false,"family":null,"url":null}},"toc":{"enable":true,"max_depth":3,"number":false,"expand":true,"init_open":true},"copyright":false,"lazyload":false,"recommendation":{"enable":false,"title":"推荐阅读","limit":3,"placeholder":"/images/wallhaven-wqery6-light.webp","skip_dirs":[]}},"colors":{"primary":"#A31F34","secondary":null},"global":{"fonts":{"chinese":{"enable":false,"family":null,"url":null},"english":{"enable":false,"family":null,"url":null}},"content_max_width":"1000px","sidebar_width":"210px","hover":{"shadow":true,"scale":false},"scroll_progress":{"bar":false,"percentage":true},"busuanzi_counter":{"enable":true,"site_pv":true,"site_uv":true,"post_pv":true},"pjax":true,"open_graph":true,"google_analytics":{"enable":false,"id":null}},"home_banner":{"enable":true,"style":"fixed","image":{"light":"https://yiqiblogimages.oss-cn-hangzhou.aliyuncs.com/home/geometry.jpg","dark":"https://yiqiblogimages.oss-cn-hangzhou.aliyuncs.com/home/night_sky.jpg"},"title":"早日毕业！","subtitle":{"text":["我们的征途是星辰大海"],"hitokoto":{"enable":false,"api":"https://v1.hitokoto.cn/?c=c&c=h&c=i&c=l"},"typing_speed":100,"backing_speed":80,"starting_delay":500,"backing_delay":1500,"loop":false,"smart_backspace":true},"text_color":{"light":"#404040","dark":"#e0e0e0"},"text_style":{"title_size":"2.8rem","subtitle_size":"1.5rem","line_height":1.2},"custom_font":{"enable":false,"family":null,"url":null},"social_links":{"enable":false,"links":{"github":"https://github.com/fengyiqi","instagram":null,"zhihu":null,"twitter":null,"email":"yiqi.feng@hotmail.com"}}},"plugins":{"feed":{"enable":false},"aplayer":{"enable":false,"type":"fixed","audios":[{"name":null,"artist":null,"url":null,"cover":null}]},"mermaid":{"enable":false,"version":"9.3.0"}},"version":"2.1.4","navbar":{"auto_hide":false,"color":{"left":"#404040","right":"#ffffff","transparency":30},"links":{"Home":{"path":"/","icon":"fa-regular fa-house"},"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"Categories":{"path":"/categories","icon":"fa-regular fa-list"},"About":{"path":"/about","icon":"fa-regular fa-face-grin-beam-sweat"}},"search":{"enable":false,"preload":true}},"page_templates":{"friends_column":2,"tags_style":"blur"},"home":{"sidebar":{"enable":true,"position":"left","first_item":"menu","announcement":null,"links":{"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"Categories":{"path":"/categories","icon":"fa-regular fa-list"},"About":{"path":"/about","icon":"fa-regular fa-face-grin-beam-sweat"}}},"article_date_format":"auto","categories":{"enable":true,"limit":3},"tags":{"enable":true,"limit":3}}};
    Global.language_ago = {"second":"%s 秒前","minute":"%s 分钟前","hour":"%s 小时前","day":"%s 天前","week":"%s 周前","month":"%s 个月前","year":"%s 年前"};
    Global.data_config = {"masonry":false};
  </script>
    
    <!--- Fontawesome Part-->
    
<link rel="stylesheet" href="/fontawesome/fontawesome.min.css">

    
<link rel="stylesheet" href="/fontawesome/brands.min.css">

    
<link rel="stylesheet" href="/fontawesome/solid.min.css">

    
<link rel="stylesheet" href="/fontawesome/regular.min.css">

    
    
    
    
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
<div class="progress-bar-container">
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fa-solid fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="main-content-container">

        <div class="main-content-header">
            <header class="navbar-container">
    
    <div class="navbar-content">
        <div class="left">
            
                <a class="logo-image" href="/">
                    <img src="/images/logo.svg">
                </a>
            
            <a class="logo-title" href="/">
                
                YiQi&#39;s Blog
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="desktop">
                <ul class="navbar-list">
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/"  >
                                    
                                        
                                            <i class="fa-regular fa-house"></i>
                                        
                                        首页
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/archives"  >
                                    
                                        
                                            <i class="fa-regular fa-archive"></i>
                                        
                                        归档
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/categories"  >
                                    
                                        
                                            <i class="fa-regular fa-list"></i>
                                        
                                        分类
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/about"  >
                                    
                                        
                                            <i class="fa-regular fa-face-grin-beam-sweat"></i>
                                        
                                        关于
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                <div class="icon-item navbar-bar">
                    <div class="navbar-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile drawer -->
    <div class="navbar-drawer">
        <ul class="drawer-navbar-list">
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="" 
                        href="/"  >
                             
                                
                                    <i class="fa-regular fa-house"></i>
                                
                                首页
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="" 
                        href="/archives"  >
                             
                                
                                    <i class="fa-regular fa-archive"></i>
                                
                                归档
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="" 
                        href="/categories"  >
                             
                                
                                    <i class="fa-regular fa-list"></i>
                                
                                分类
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="" 
                        href="/about"  >
                             
                                
                                    <i class="fa-regular fa-face-grin-beam-sweat"></i>
                                
                                关于
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            

        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="main-content-body">

            

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="post-page-container">
        <div class="article-content-container">

            
            
                <div class="article-title">
                    <h1 class="article-title-regular">CUDA编程05: CUDA流与统一内存</h1>
                </div>
            
                
            

            
                <div class="article-header">
                    <div class="avatar">
                        <img src="/images/logo.svg">
                    </div>
                    <div class="info">
                        <div class="author">
                            <span class="name">YiQi</span>
                            
                                <span class="author-label">管理员</span>
                            
                        </div>
                        <div class="meta-info">
                            <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="desktop">2023-01-16 13:49:31</span>
        <span class="mobile">2023-01-16 13:49</span>
        <span class="hover-info">创建</span>
    </span>
    
        <span class="article-date article-meta-item">
            <i class="fa-regular fa-wrench"></i>&nbsp;
            <span class="desktop">2023-03-11 22:57:58</span>
            <span class="mobile">2023-03-11 22:57</span>
            <span class="hover-info">更新</span>
        </span>
    

    
        <span class="article-categories article-meta-item">
            <i class="fa-regular fa-folders"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/categories/CUDA/">CUDA</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fa-regular fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/CUDA/">CUDA</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/C/">C</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/C/">C++</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fa-regular fa-typewriter"></i>&nbsp;<span>3.8k 字</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fa-regular fa-clock"></i>&nbsp;<span>17 分钟</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                        </div>
                    </div>
                </div>
            

            <div class="article-content markdown-body">
                <h2 id="CUDA流概述"><a href="#CUDA流概述" class="headerlink" title="CUDA流概述"></a>CUDA流概述</h2><p>一个CUDA流指的是由主机发出的在一个设备中执行的CUDA操作（即和CUDA有关的操作，如主机-设备数据传输和核函数执行）序列。</p>
<p>任何CUDA操作都存在于某个CUDA流中，要么是默认流（default stream，也称为空流，null stream），要么是明确指定的非空流。</p>
<p>非默认的CUDA流是在主机端产生与销毁的。一个CUDA流由类型为<code>cudaStream_t</code>的变量表示，它可由如下运行时API函数产生和销毁：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaStreamCreate</span><span class="params">(cudaStream_t*)</span></span>;</span><br><span class="line"><span class="function">cudaError_t <span class="title">cudaStreamDestroy</span><span class="params">(cudaStream_t)</span></span>;</span><br></pre></td></tr></table></figure></div>

<blockquote>
<p>没错，产生时用指针，销毁时用变量</p>
</blockquote>
<p>为了检查一个CUDA流中的所有操作是否都在设备中执行完毕，CUDA运行时API提供了如下两个函数：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaStreamSynchronize</span><span class="params">(cudaStream_t stream)</span></span>;</span><br><span class="line"><span class="function">cudaError_t <span class="title">cudaStreamQuery</span><span class="params">(cudaStream_t stream)</span></span>;</span><br></pre></td></tr></table></figure></div>

<p><code>cudaStreamSynchronize()</code>会强制阻塞主机，直到CUDA流stream中的所有操作都执行完毕。函数<code>cudaStreamQuery()</code>不会阻塞主机，只是检查CUDA流stream中的所有操作是否都执行完毕。若是，返回<code>cudaSuccess</code>，否则返回<code>cudaErrorReady</code>。</p>
<h2 id="在默认流中重叠主机和设备计算"><a href="#在默认流中重叠主机和设备计算" class="headerlink" title="在默认流中重叠主机和设备计算"></a>在默认流中重叠主机和设备计算</h2><p>以数组相加举例：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cudaMemcpy</span>(d_x, h_x, M, cudaMemcpyHostToDevice);</span><br><span class="line"><span class="built_in">cudaMemcpy</span>(d_y, h_y, M, cudaMemcpyHostToDevice);</span><br><span class="line">sum&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(d_x, d_y, d_z, N);</span><br><span class="line"><span class="built_in">cudaMemcpy</span>(h_z, d_z, M, cudaMemcpyDeviceToHost);</span><br></pre></td></tr></table></figure></div>

<ul>
<li>从主机角度看，数据传输是同步的（阻塞的），即要等待<code>cudaMemcpy(d_x, h_x, M, cudaMemcpyHostToDevice)</code>执行完再往前走。</li>
<li>核函数的启动是异步的（非阻塞的），即主机发出命令<code>sum&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(d_x, d_y, d_z, N)</code>之后不会等待该命令执行完毕，而会立刻得到程序的控制权。</li>
<li>紧接着主机发出<code>cudaMemcpy(h_z, d_z, M, cudaMemcpyDeviceToHost)</code>，该命令不会被立即执行，而必须等待前一个CUDA操作（即核函数的调用）执行完毕才会开始执行。</li>
</ul>
<p>由此可知，<strong>主机在发出核函数调用的命令之后，会立刻发出下一个命令</strong>。在上面的例子中，下一个命令是进行数据传输，但从设备的角度来看必须等待核函数执行完毕。<strong>如果下—个命令是主机中的某个计算任务，那么主机就会在设备执行核函数的同时去进行一些计算</strong>。这样，主机和设备就可以同时进行计算。设备完全不知道在它执行核函数时，主机偷偷地做了些计算。</p>
<p>例如下面的代码（完整代码见 <a class="link"   target="_blank" rel="noopener" href="https://github.com/fengyiqi/cppCUDA/blob/master/tutorials/host_kernel.cu" >host_kernel.cu <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>）：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">cpu_sum</span><span class="params">(<span class="type">const</span> real *x, <span class="type">const</span> real *y, real *z, <span class="type">const</span> <span class="type">int</span> N_host)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> n = <span class="number">0</span>; n &lt; N_host; ++n) &#123;</span><br><span class="line">        z[n] = x[n] + y[n];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> __global__ <span class="title">gpu_sum</span><span class="params">(<span class="type">const</span> real *x, <span class="type">const</span> real *y, real *z)</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> n = blockDim.x * blockIdx.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span> (n &lt; N) &#123;</span><br><span class="line">        z[n] = x[n] + y[n];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">timing</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> real *h_x, <span class="type">const</span> real *h_y, real *h_z,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> real *d_x, <span class="type">const</span> real *d_y, real *d_z,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">int</span> ratio, <span class="type">bool</span> overlap</span></span></span><br><span class="line"><span class="params"><span class="function">)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 一些与计时相关的代码</span></span><br><span class="line">        <span class="keyword">if</span> (!overlap) &#123;</span><br><span class="line">            <span class="built_in">cpu_sum</span>(h_x, h_y, h_z, N / ratio);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        gpu_sum&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(d_x, d_y, d_z);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (overlap) &#123;</span><br><span class="line">            <span class="built_in">cpu_sum</span>(h_x, h_y, h_z, N / ratio);</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="comment">// 一些与计时相关的代码</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>选择<code>overlap</code>为真时，将在调用核函数之后调用一个主机端函数，从而达到并发执行的效果。</p>
<h2 id="用非默认CUDA流重叠多个核函数执行"><a href="#用非默认CUDA流重叠多个核函数执行" class="headerlink" title="用非默认CUDA流重叠多个核函数执行"></a>用非默认CUDA流重叠多个核函数执行</h2><p>同一个CUDA流中的CUDA操作在设备中是顺序执行的，故同一个CUDA流中的核函数也必须在设备中顺序执行。要实现多个核函数之间的并行必须使用多个CUDA流。</p>
<h3 id="函数执行配置中的流参数"><a href="#函数执行配置中的流参数" class="headerlink" title="函数执行配置中的流参数"></a>函数执行配置中的流参数</h3><p>调用一个名为<code>my_kernel</code>的核函数有如下三种方式：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">my_kernel&lt;&lt;&lt;N_grid, N_block&gt;&gt;&gt;(函数参数);</span><br><span class="line">my_kernel&lt;&lt;&lt;N_grid, N_block, N_shared&gt;&gt;&gt;(函数参数);</span><br><span class="line">my_kernel&lt;&lt;&lt;N_grid, N_block, N_shared, stream_id&gt;&gt;&gt;(函数参数);</span><br></pre></td></tr></table></figure></div>
<p>前两种方式属于在默认流中不使用和使用动态共享内存的方式。第三种调用方式说明核函数在编号为<code>stream_id</code>的CUDA流中执行，并且使用了<code>N_shared</code>动态共享内存。如果不想使用动态共享内存，调用方式为</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">my_kernel&lt;&lt;&lt;N_grid, N_block, <span class="number">0</span>, stream_id&gt;&gt;&gt;(函数参数);</span><br></pre></td></tr></table></figure></div>

<h3 id="叠多个核函数的例子"><a href="#叠多个核函数的例子" class="headerlink" title="叠多个核函数的例子"></a>叠多个核函数的例子</h3><p>例如下面的代码（完整代码见 <a class="link"   target="_blank" rel="noopener" href="https://github.com/fengyiqi/cppCUDA/blob/master/tutorials/kernel_kernel.cu" >kernel_kernel.cu <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>）</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建CUDA流，调用核函数，销毁CUDA流</span></span><br><span class="line">cudaStream_t streams[MAX_NUM_STREAMS];</span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> n = <span class="number">0</span> ; n &lt; MAX_NUM_STREAMS; ++n) &#123;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaStreamCreate</span>(&amp;(streams[n])));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> num = <span class="number">1</span>; num &lt;= MAX_NUM_STREAMS; ++num) &#123;</span><br><span class="line">    <span class="built_in">timing</span>(d_x, d_y, d_z, num);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (<span class="type">int</span> n = <span class="number">0</span> ; n &lt; MAX_NUM_STREAMS; ++n) &#123;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaStreamDestroy</span>(streams[n]));</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">timing</span><span class="params">(<span class="type">const</span> real *d_x, <span class="type">const</span> real *d_y, real *d_z, <span class="type">const</span> <span class="type">int</span> num)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="comment">// 一些与计时相关的代码</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> n = <span class="number">0</span>; n &lt; num; ++n) &#123;</span><br><span class="line">            <span class="type">int</span> offset = n * N1;</span><br><span class="line">            add&lt;&lt;&lt;grid_size, block_size, <span class="number">0</span>, streams[n]&gt;&gt;&gt;(d_x + offset, d_y + offset, d_z + offset);</span><br><span class="line">        &#125;</span><br><span class="line">    <span class="comment">// 一些与计时相关的代码       </span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>这个程序比较了随着CUDA流增多（数据量也成倍增多）执行时间的变化情况。一开始执行时间并没有明显增加，说明使用同样的时间可以处理更多的数据。</p>
<p>Tesla K40有15个SM，作者使用Tesla K40测试时，在流数量达到15时，加速就不是很明显，似乎说明一个核函数占用了一个SM，如下图所示：</p>
<p align="center">
    <img src="https://yiqiblogimages.oss-cn-hangzhou.aliyuncs.com/cuda/teslak40_sm.png" width=100% >
</p>

<p>上面说明制约GPU加速的是计算资源，另外还有一个因素是单个GPU中能够并发执行的核函数个数上限。不同计算能力这个上限不同，比如计算能力7.5对应的是128。K40计算能力3.5，最大核函数并发数目为32，将上述程序的单个核函数线程束由1024降为128，测试结果如下：</p>
<p align="center">
    <img src="https://yiqiblogimages.oss-cn-hangzhou.aliyuncs.com/cuda/teslak40_smlimit.png" width=100% >
</p>

<h2 id="用非默认CUDA流重叠核函数的执行与数据传递"><a href="#用非默认CUDA流重叠核函数的执行与数据传递" class="headerlink" title="用非默认CUDA流重叠核函数的执行与数据传递"></a>用非默认CUDA流重叠核函数的执行与数据传递</h2><h3 id="不可分页主机内存与异步的数据传输函数"><a href="#不可分页主机内存与异步的数据传输函数" class="headerlink" title="不可分页主机内存与异步的数据传输函数"></a>不可分页主机内存与异步的数据传输函数</h3><p>要实现核函数执行与数据传输的并发（重叠），必须让这两个操作处于不同的非默认流，而且数据传输必须使用<code>cudaMemcpy()</code>函数的异步版本，即<code>cudaMemcpyAsync()</code>函数。异步传输由GPU中的DMA（direct memory access）直接实现，不需要主机参与。异步传输函数原型为：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaMemcpyAsync</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">void</span>                *dist,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">void</span>          *src,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">size_t</span>              count,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">enum</span> cudaMemcpyKind kind,</span></span></span><br><span class="line"><span class="params"><span class="function">    cudaStream_t        stream</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span></span><br></pre></td></tr></table></figure></div>

<p>在使用异步的数据传输函数时，需要将主机内存定义为不可分页内存（non-pageable memory）或者固定内存（pinned memory）。操作系统有权在一个程序运行期间改变程序中使用的可分页主机内存的物理地址。相反，若主机中的内存声明为不可分页内存，则在程序运行期间其物理地址将保持不变。如果将可分页内存传给<code>cudaMemcpyAsync()</code>函数，则会导致同步传输，达不到重叠核函数执行与数据传输的效果。</p>
<p>不可分页主机内存的分配可以由以下两个CUDA运行时API函数中的任何<br>一个实现：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaMallocHost</span><span class="params">(<span class="type">void</span>** ptr, <span class="type">sizt_t</span>, size)</span></span>;</span><br><span class="line"><span class="function">cudaError_t <span class="title">cudaHostAlloc</span><span class="params">(<span class="type">void</span>** ptr, <span class="type">size_t</span> size, <span class="type">size_t</span> flags)</span></span>;</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>若函数<code>cudaHostAlloc()</code>的第三个参数取默认值<code>cudaHostAllocDefault</code>则以上两个函数完全等价，这里不讨论取其他值的用法。</p>
</blockquote>
<p>以上分配的主机内存由如下函数释放：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaFreeHost</span><span class="params">(<span class="type">void</span>* ptr)</span></span>;</span><br></pre></td></tr></table></figure></div>

<h3 id="重叠核函数执行与数据传输的例子"><a href="#重叠核函数执行与数据传输的例子" class="headerlink" title="重叠核函数执行与数据传输的例子"></a>重叠核函数执行与数据传输的例子</h3><p>我们将主机向设备传输数据记为H2D，核函数计算记为KER，设备传输数据到主机记为D2H。一个可行的并发方案是，将数据分为多份，并发传输数据并计算。比如将数据分为两份，使用两个CUDA流：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Stream 1: H2D -&gt; KER -&gt; D2H</span><br><span class="line">Stream 2:        H2D -&gt; KER -&gt; D2H</span><br></pre></td></tr></table></figure></div>
<p>如果H2D、KER和D2H耗时相同，那么我们相当于把总共6步的操作变成了4步，加速比为1.5。类似的，使用4个流时，加速比为2。理论上最大加速比为3（三步耗时相同的情况下）。</p>
<p>代码示例如下（完整代码见 <a class="link"   target="_blank" rel="noopener" href="https://github.com/fengyiqi/cppCUDA/blob/master/tutorials/kernel_transfer.cu" >kernel_transfer.cu <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>）：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">timing</span><span class="params">(<span class="type">const</span> real *h_x, <span class="type">const</span> real *h_y, real *h_z, real *d_x, real *d_y, real *d_z, <span class="type">const</span> <span class="type">int</span> num)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 一些与计时相关的代码</span></span><br><span class="line">            <span class="type">int</span> offset = i * N1;</span><br><span class="line">            <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpyAsync</span>(d_x + offset, h_x + offset, M1, cudaMemcpyHostToDevice, streams[i]));</span><br><span class="line">            <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpyAsync</span>(d_y + offset, h_y + offset, M1, cudaMemcpyHostToDevice, streams[i]));</span><br><span class="line"></span><br><span class="line">            <span class="type">int</span> block_size = <span class="number">128</span>;</span><br><span class="line">            <span class="type">int</span> grid_size = (N1 - <span class="number">1</span>) / block_size + <span class="number">1</span>;</span><br><span class="line">            add&lt;&lt;&lt;grid_size, block_size, <span class="number">0</span>, streams[i]&gt;&gt;&gt;(d_x + offset, d_y + offset, d_z + offset, N1);</span><br><span class="line"></span><br><span class="line">            <span class="built_in">CHECK</span>(<span class="built_in">cudaMemcpyAsync</span>(h_z + offset, d_z + offset, M1, cudaMemcpyDeviceToHost, streams[i]));</span><br><span class="line">        <span class="comment">// 一些与计时相关的代码</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>作者的测试结果如下：</p>
<p align="center">
    <img src="https://yiqiblogimages.oss-cn-hangzhou.aliyuncs.com/cuda/teslak40_transfer.png" width=100% >
</p>


<h2 id="统一内存简介"><a href="#统一内存简介" class="headerlink" title="统一内存简介"></a>统一内存简介</h2><p>统一内存是一种自动分配位置的，主机和设备都可访问的内存。从开普勒架构开始得到支持，开普勒和麦克斯韦架构的统一内存称为第一代统一内存，从帕斯卡架构开始的统一内存称为第二代统一内存。目前Windows平台对统一内存的支持不完善，Linux平台支持较好。使用统一内存的话，可对显存进行超量分配，超出显存的部分可能存放在主机上。</p>
<h3 id="统一内存的使用方法"><a href="#统一内存的使用方法" class="headerlink" title="统一内存的使用方法"></a>统一内存的使用方法</h3><h4 id="动态统一内存"><a href="#动态统一内存" class="headerlink" title="动态统一内存"></a>动态统一内存</h4><p>统一内存需要在主机端定义或分配，使用CUDA运行时API函数：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaMallocManaged</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">void</span>        **devPtr,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">size_t</span>      size,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">unsigned</span>    flages = <span class="number">0</span></span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span></span><br></pre></td></tr></table></figure></div>
<ul>
<li>相比<code>cudaMalloc()</code>，该函数多了一个可选参数<code>flags</code>，默认值为<code>cudaMemAttachGlobal</code></li>
<li>统一内存释放依然使用<code>cudaFree()</code></li>
</ul>
<p>以数组相加为例，主函数代码如下：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> N = <span class="number">100000000</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> M = <span class="built_in">sizeof</span>(<span class="type">double</span>) * N;</span><br><span class="line">    <span class="type">double</span> *x, *y, *z;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMallocManaged</span>((<span class="type">void</span> **)&amp;x, M));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMallocManaged</span>((<span class="type">void</span> **)&amp;y, M));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMallocManaged</span>((<span class="type">void</span> **)&amp;z, M));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> n = <span class="number">0</span>; n &lt; N; ++n) &#123;</span><br><span class="line">        x[n] = a;</span><br><span class="line">        y[n] = b;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> block_size = <span class="number">128</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> grid_size = N / block_size;</span><br><span class="line">    add&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(x, y, z);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">    <span class="built_in">check</span>(z, N);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(x));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(y));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(z));</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h4 id="静态统一内存"><a href="#静态统一内存" class="headerlink" title="静态统一内存"></a>静态统一内存</h4><p>要定义静态统一内存，只需要在修饰符<code>__device__</code>的基础上再加上修饰符<code>__managed__</code>即可。这样的变量要在任何函数外部定义，本文件可见。例如：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">__device__ __managed__ <span class="type">int</span> ret[<span class="number">1000</span>];</span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">AplusB</span><span class="params">(<span class="type">int</span> a, <span class="type">int</span> b)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    AplusB&lt;&lt;&lt;<span class="number">1</span>, <span class="number">1000</span>&gt;&gt;&gt;(<span class="number">10</span>, <span class="number">1000</span>);</span><br><span class="line">    <span class="built_in">cudaDeviceSynchronize</span>();</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">1000</span>; i++)</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d: A + B = %d\n&quot;</span>, i ret[i]);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<h3 id="使用统一内存申请超量内存"><a href="#使用统一内存申请超量内存" class="headerlink" title="使用统一内存申请超量内存"></a>使用统一内存申请超量内存</h3><p>该功能无法在Windows平台上使用</p>
<h4 id="测试1"><a href="#测试1" class="headerlink" title="测试1"></a>测试1</h4><p>对于程序：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;error.cuh&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdint.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">30</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> n = <span class="number">1</span>; n &lt;= N; ++n) &#123;</span><br><span class="line">        <span class="type">const</span> <span class="type">size_t</span> size = <span class="built_in">size_t</span>(n) * <span class="number">1024</span> * <span class="number">1024</span> * <span class="number">1024</span>;</span><br><span class="line">        <span class="type">uint64_t</span> *x;</span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> UNIFIED</span></span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaMallocManaged</span>(&amp;x, size));</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(x));</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Allocated %d GB unified memory without touch.\n&quot;</span>, n);</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaMalloc</span>(&amp;x, size));</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(x));</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Allocate %d GB device memory.\n&quot;</span>, n);</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>不使用统一内存的情况下，输出如下：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Allocate 1 GB device memory.</span><br><span class="line">Allocate 2 GB device memory.</span><br><span class="line">Allocate 3 GB device memory.</span><br><span class="line">Allocate 4 GB device memory.</span><br><span class="line">Allocate 5 GB device memory.</span><br><span class="line">Allocate 6 GB device memory.</span><br><span class="line">Allocate 7 GB device memory.</span><br><span class="line">CUDA Error: </span><br><span class="line">    File:       tutorials/over_subscription1.cu</span><br><span class="line">    Line:       18</span><br><span class="line">    Error code: 2</span><br><span class="line">    Error text: out of memory</span><br></pre></td></tr></table></figure></div>
<p>因为显存只有8G，所以分配超过8G显存就会报错。使用统一内存的情况下，输出如下：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">Allocated 1 GB unified memory without touch.</span><br><span class="line">Allocated 2 GB unified memory without touch.</span><br><span class="line">Allocated 3 GB unified memory without touch.</span><br><span class="line">Allocated 4 GB unified memory without touch.</span><br><span class="line">Allocated 5 GB unified memory without touch.</span><br><span class="line">Allocated 6 GB unified memory without touch.</span><br><span class="line">Allocated 7 GB unified memory without touch.</span><br><span class="line">Allocated 8 GB unified memory without touch.</span><br><span class="line">Allocated 9 GB unified memory without touch.</span><br><span class="line">Allocated 10 GB unified memory without touch.</span><br><span class="line">Allocated 11 GB unified memory without touch.</span><br><span class="line">Allocated 12 GB unified memory without touch.</span><br><span class="line">Allocated 13 GB unified memory without touch.</span><br><span class="line">Allocated 14 GB unified memory without touch.</span><br><span class="line">Allocated 15 GB unified memory without touch.</span><br><span class="line">Allocated 16 GB unified memory without touch.</span><br><span class="line">Allocated 17 GB unified memory without touch.</span><br><span class="line">Allocated 18 GB unified memory without touch.</span><br><span class="line">Allocated 19 GB unified memory without touch.</span><br><span class="line">Allocated 20 GB unified memory without touch.</span><br><span class="line">Allocated 21 GB unified memory without touch.</span><br><span class="line">Allocated 22 GB unified memory without touch.</span><br><span class="line">Allocated 23 GB unified memory without touch.</span><br><span class="line">Allocated 24 GB unified memory without touch.</span><br><span class="line">Allocated 25 GB unified memory without touch.</span><br><span class="line">Allocated 26 GB unified memory without touch.</span><br><span class="line">Allocated 27 GB unified memory without touch.</span><br><span class="line">Allocated 28 GB unified memory without touch.</span><br><span class="line">Allocated 29 GB unified memory without touch.</span><br><span class="line">Allocated 30 GB unified memory without touch.</span><br></pre></td></tr></table></figure></div>
<p>虽然内存加显存加起来不到30GB，但显示可以分配30GB，是因为<code>cudaMallocManaged()</code>只是预定了一段地址空间，而统一内存的实际分配发生在主机或设备第一次访问预留的内存时。</p>
<h4 id="测试2"><a href="#测试2" class="headerlink" title="测试2"></a>测试2</h4><p>这次使用核函数进行实际分配，测试程序如下：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;error.cuh&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdint.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">30</span>;</span><br><span class="line"></span><br><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">gpu_touch</span><span class="params">(<span class="type">uint64_t</span> *x, <span class="type">const</span> <span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">    <span class="type">const</span> <span class="type">size_t</span> i = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span> (i &lt; size) &#123;</span><br><span class="line">        x[i] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> n = <span class="number">1</span>; n &lt;= N; ++n) &#123;</span><br><span class="line">        <span class="type">const</span> <span class="type">size_t</span> memory_size = <span class="built_in">size_t</span>(n) * <span class="number">1024</span> * <span class="number">1024</span> * <span class="number">1024</span>;</span><br><span class="line">        <span class="type">const</span> <span class="type">size_t</span> data_size = memory_size / <span class="built_in">sizeof</span>(<span class="type">uint64_t</span>);</span><br><span class="line">        <span class="type">uint64_t</span> *x;</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaMallocManaged</span>(&amp;x, memory_size));</span><br><span class="line">        gpu_touch&lt;&lt;&lt;(data_size - <span class="number">1</span>) / <span class="number">1028</span> + <span class="number">1</span>, <span class="number">1024</span>&gt;&gt;&gt;(x, data_size);</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaGetLastError</span>());</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(x));</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Allocated %d GB unified memory with GPU touch.\n&quot;</span>, n);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>输出如下：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">Allocated 1 GB unified memory with GPU touch.</span><br><span class="line">Allocated 2 GB unified memory with GPU touch.</span><br><span class="line">Allocated 3 GB unified memory with GPU touch.</span><br><span class="line">Allocated 4 GB unified memory with GPU touch.</span><br><span class="line">Allocated 5 GB unified memory with GPU touch.</span><br><span class="line">Allocated 6 GB unified memory with GPU touch.</span><br><span class="line">Allocated 7 GB unified memory with GPU touch.</span><br><span class="line">Allocated 8 GB unified memory with GPU touch.</span><br><span class="line">Allocated 9 GB unified memory with GPU touch.</span><br><span class="line">Allocated 10 GB unified memory with GPU touch.</span><br><span class="line">Allocated 11 GB unified memory with GPU touch.</span><br><span class="line">Allocated 12 GB unified memory with GPU touch.</span><br><span class="line">Allocated 13 GB unified memory with GPU touch.</span><br><span class="line">Allocated 14 GB unified memory with GPU touch.</span><br><span class="line">Allocated 15 GB unified memory with GPU touch.</span><br><span class="line">Allocated 16 GB unified memory with GPU touch.</span><br><span class="line">Allocated 17 GB unified memory with GPU touch.</span><br><span class="line">CUDA Error: </span><br><span class="line">    File:       tutorials/over_subscription2.cu</span><br><span class="line">    Line:       26</span><br><span class="line">    Error code: 700</span><br><span class="line">    Error text: an illegal memory access was encountered</span><br></pre></td></tr></table></figure></div>
<p>当实际分配的内存超出容量时就报错了。</p>
<h4 id="测试3"><a href="#测试3" class="headerlink" title="测试3"></a>测试3</h4><p>这次使用主机函数进行实际分配，代码如下：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;error.cuh&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdint.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">30</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">cpu_touch</span><span class="params">(<span class="type">uint64_t</span> *x, <span class="type">size_t</span> size)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; size / <span class="built_in">sizeof</span>(<span class="type">uint64_t</span>); i++) &#123;</span><br><span class="line">        x[i] = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> n = <span class="number">1</span>; n &lt;= N; ++n) &#123;</span><br><span class="line">        <span class="type">size_t</span> size = <span class="built_in">size_t</span>(n) * <span class="number">1024</span> * <span class="number">1024</span> * <span class="number">1024</span>;</span><br><span class="line">        <span class="type">uint64_t</span> *x;</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaMallocManaged</span>(&amp;x, size));</span><br><span class="line">        <span class="built_in">cpu_touch</span>(x, size);</span><br><span class="line">        <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(x));</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Allocated %d GB unified memory with CPU touch.\n&quot;</span>, n);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>
<p>输出如下：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Allocated 1 GB unified memory with CPU touch.</span><br><span class="line">Allocated 2 GB unified memory with CPU touch.</span><br><span class="line">Allocated 3 GB unified memory with CPU touch.</span><br><span class="line">Allocated 4 GB unified memory with CPU touch.</span><br><span class="line">Allocated 5 GB unified memory with CPU touch.</span><br><span class="line">Allocated 6 GB unified memory with CPU touch.</span><br><span class="line">Allocated 7 GB unified memory with CPU touch.</span><br><span class="line">Allocated 8 GB unified memory with CPU touch.</span><br><span class="line">Allocated 9 GB unified memory with CPU touch.</span><br><span class="line">Allocated 10 GB unified memory with CPU touch.</span><br></pre></td></tr></table></figure></div>
<p>这里只分配了10GB，说明使用主机分配内存的话，不会自动使用设备内存。</p>
<h3 id="优化使用统一内存的程序"><a href="#优化使用统一内存的程序" class="headerlink" title="优化使用统一内存的程序"></a>优化使用统一内存的程序</h3><p>CUDA的统一内存机制可以部分地自动做到数据与处理器接近，但很多情况下需要手动给编译器一些提示，如使用运行时API函数<code>cudaMemAdvise()</code>和<code>cudaMemPrefetchAsync()</code>，这里只讲后者</p>
<p>函数<code>cudaMemPrefetchAsync()</code>的原型为：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">cudaError_t <span class="title">cudaMemPrefetchAsync</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">const</span> <span class="type">void</span>      *devPtr,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">size_t</span>          count,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">int</span>             dstDevice,</span></span></span><br><span class="line"><span class="params"><span class="function">    cudaStream_t    strem</span></span></span><br><span class="line"><span class="params"><span class="function">)</span></span></span><br></pre></td></tr></table></figure></div>

<p>示例程序如下：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> device_id = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaGetDevice</span>(&amp;device_id));</span><br><span class="line">	  </span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> N = <span class="number">100000000</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> M = <span class="built_in">sizeof</span>(<span class="type">double</span>) * N;</span><br><span class="line">    <span class="type">double</span> *x, *y, *z;</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMallocManaged</span>((<span class="type">void</span> **)&amp;x, M));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMallocManaged</span>((<span class="type">void</span> **)&amp;y, M));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMallocManaged</span>((<span class="type">void</span> **)&amp;z, M));</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> n = <span class="number">0</span>; n &lt; N; ++n) &#123;</span><br><span class="line">        x[n] = a;</span><br><span class="line">        y[n] = b;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> block_size = <span class="number">128</span>;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> grid_size = N / block_size;</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemPrefetchAsync</span>(x, M, device_id, <span class="literal">NULL</span>));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemPrefetchAsync</span>(y, M, device_id, <span class="literal">NULL</span>));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemPrefetchAsync</span>(z, M, device_id, <span class="literal">NULL</span>));</span><br><span class="line">    </span><br><span class="line">    add&lt;&lt;&lt;grid_size, block_size&gt;&gt;&gt;(x, y, z);</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaMemPrefetchAsync</span>(z, M, cudaCpuDeviceId, <span class="literal">NULL</span>));</span><br><span class="line"></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaDeviceSynchronize</span>());</span><br><span class="line">    <span class="built_in">check</span>(z, N);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(x));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(y));</span><br><span class="line">    <span class="built_in">CHECK</span>(<span class="built_in">cudaFree</span>(z));</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>




            </div>

            

            
                <ul class="post-tags-box">
                    
                        <li class="tag-item">
                            <a href="/tags/CUDA/">#CUDA</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/C/">#C</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/C/">#C++</a>&nbsp;
                        </li>
                    
                </ul>
            

            

            
                <div class="article-nav">
                    
                        <div class="article-prev">
                            <a class="prev"
                            rel="prev"
                            href="/2023/cpptemplate1/"
                            >
                                <span class="left arrow-icon flex-center">
                                    <i class="fa-solid fa-chevron-left"></i>
                                </span>
                                <span class="title flex-center">
                                    <span class="post-nav-title-item">C++模板系列01：模板的特化与偏特化</span>
                                    <span class="post-nav-item">上一篇</span>
                                </span>
                            </a>
                        </div>
                    
                    
                        <div class="article-next">
                            <a class="next"
                            rel="next"
                            href="/2023/cuda4/"
                            >
                                <span class="title flex-center">
                                    <span class="post-nav-title-item">CUDA编程04: 线程束基本函数与协作组</span>
                                    <span class="post-nav-item">下一篇</span>
                                </span>
                                <span class="right arrow-icon flex-center">
                                    <i class="fa-solid fa-chevron-right"></i>
                                </span>
                            </a>
                        </div>
                    
                </div>
            


            
        </div>

        
            <div class="toc-content-container">
                <div class="post-toc-wrap">
    <div class="post-toc">
        <div class="toc-title">此页目录</div>
        <div class="page-title">CUDA编程05: CUDA流与统一内存</div>
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#CUDA%E6%B5%81%E6%A6%82%E8%BF%B0"><span class="nav-text">CUDA流概述</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9C%A8%E9%BB%98%E8%AE%A4%E6%B5%81%E4%B8%AD%E9%87%8D%E5%8F%A0%E4%B8%BB%E6%9C%BA%E5%92%8C%E8%AE%BE%E5%A4%87%E8%AE%A1%E7%AE%97"><span class="nav-text">在默认流中重叠主机和设备计算</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%94%A8%E9%9D%9E%E9%BB%98%E8%AE%A4CUDA%E6%B5%81%E9%87%8D%E5%8F%A0%E5%A4%9A%E4%B8%AA%E6%A0%B8%E5%87%BD%E6%95%B0%E6%89%A7%E8%A1%8C"><span class="nav-text">用非默认CUDA流重叠多个核函数执行</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%87%BD%E6%95%B0%E6%89%A7%E8%A1%8C%E9%85%8D%E7%BD%AE%E4%B8%AD%E7%9A%84%E6%B5%81%E5%8F%82%E6%95%B0"><span class="nav-text">函数执行配置中的流参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8F%A0%E5%A4%9A%E4%B8%AA%E6%A0%B8%E5%87%BD%E6%95%B0%E7%9A%84%E4%BE%8B%E5%AD%90"><span class="nav-text">叠多个核函数的例子</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%94%A8%E9%9D%9E%E9%BB%98%E8%AE%A4CUDA%E6%B5%81%E9%87%8D%E5%8F%A0%E6%A0%B8%E5%87%BD%E6%95%B0%E7%9A%84%E6%89%A7%E8%A1%8C%E4%B8%8E%E6%95%B0%E6%8D%AE%E4%BC%A0%E9%80%92"><span class="nav-text">用非默认CUDA流重叠核函数的执行与数据传递</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%8D%E5%8F%AF%E5%88%86%E9%A1%B5%E4%B8%BB%E6%9C%BA%E5%86%85%E5%AD%98%E4%B8%8E%E5%BC%82%E6%AD%A5%E7%9A%84%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E5%87%BD%E6%95%B0"><span class="nav-text">不可分页主机内存与异步的数据传输函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E9%87%8D%E5%8F%A0%E6%A0%B8%E5%87%BD%E6%95%B0%E6%89%A7%E8%A1%8C%E4%B8%8E%E6%95%B0%E6%8D%AE%E4%BC%A0%E8%BE%93%E7%9A%84%E4%BE%8B%E5%AD%90"><span class="nav-text">重叠核函数执行与数据传输的例子</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BB%9F%E4%B8%80%E5%86%85%E5%AD%98%E7%AE%80%E4%BB%8B"><span class="nav-text">统一内存简介</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%BB%9F%E4%B8%80%E5%86%85%E5%AD%98%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95"><span class="nav-text">统一内存的使用方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8%E7%BB%9F%E4%B8%80%E5%86%85%E5%AD%98%E7%94%B3%E8%AF%B7%E8%B6%85%E9%87%8F%E5%86%85%E5%AD%98"><span class="nav-text">使用统一内存申请超量内存</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BC%98%E5%8C%96%E4%BD%BF%E7%94%A8%E7%BB%9F%E4%B8%80%E5%86%85%E5%AD%98%E7%9A%84%E7%A8%8B%E5%BA%8F"><span class="nav-text">优化使用统一内存的程序</span></a></li></ol></li></ol>

    </div>
</div>
            </div>
        
    </div>
</div>


                

            </div>
            
            

        </div>

        <div class="main-content-footer">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info">
            &copy;
            
              <span>2022</span>
              -
            
            2023&nbsp;&nbsp;<i class="fa-solid fa-cog fa-spin" style="--fa-animation-duration: 15s;"></i>&nbsp;&nbsp;<a href="/">YiQi</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv" class="busuanzi_container_site_uv">
                        访问人数&nbsp;<span id="busuanzi_value_site_uv" class="busuanzi_value_site_uv"></span>
                    </span>
                
                
                    <span id="busuanzi_container_site_pv" class="busuanzi_container_site_pv">
                        总访问量&nbsp;<span id="busuanzi_value_site_pv" class="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="theme-info info-item">
            <span class="powered-by-container">由 <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" href="https://hexo.io">Hexo</a> 驱动</span>
                <br>
            <span class="theme-version-container">主题&nbsp;<a class="theme-version" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.1.4</a>
        </div>
        
        
        
            <div id="start_div" style="display:none">
                2022/12/21 11:45:14
            </div>
            <div>
                博客已运行 <span class="odometer" id="runtime_days" ></span> 天 <span class="odometer" id="runtime_hours"></span> 小时 <span class="odometer" id="runtime_minutes"></span> 分钟 <span class="odometer" id="runtime_seconds"></span> 秒
            </div>
        
        
        
            <script async data-pjax>
                try {
                    function odometer_init() {
                    const elements = document.querySelectorAll('.odometer');
                    elements.forEach(el => {
                        new Odometer({
                            el,
                            format: '( ddd).dd',
                            duration: 200
                        });
                    });
                    }
                    odometer_init();
                } catch (error) {}
            </script>
        
        
        
    </div>  
</footer>
        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="article-tools-list">
        <!-- TOC aside toggle -->
        
            <li class="right-bottom-tools page-aside-toggle">
                <i class="fa-regular fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
    </ul>
</div>

        </div>
    

    <div class="right-side-tools-container">
        <div class="side-tools-container">
    <ul class="hidden-tools-list">
        <li class="right-bottom-tools tool-font-adjust-plus flex-center">
            <i class="fa-regular fa-magnifying-glass-plus"></i>
        </li>

        <li class="right-bottom-tools tool-font-adjust-minus flex-center">
            <i class="fa-regular fa-magnifying-glass-minus"></i>
        </li>

        <li class="right-bottom-tools tool-expand-width flex-center">
            <i class="fa-regular fa-expand"></i>
        </li>

        <li class="right-bottom-tools tool-dark-light-toggle flex-center">
            <i class="fa-regular fa-moon"></i>
        </li>

        <!-- rss -->
        

        

        <li class="right-bottom-tools tool-scroll-to-bottom flex-center">
            <i class="fa-regular fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="visible-tools-list">
        <li class="right-bottom-tools toggle-tools-list flex-center">
            <i class="fa-regular fa-cog fa-spin"></i>
        </li>
        
            <li class="right-bottom-tools tool-scroll-to-top flex-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
        
    </ul>
</div>

    </div>

    <div class="image-viewer-container">
    <img src="">
</div>


    


</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/layouts/navbarShrink.js"></script>

<script src="/js/tools/scrollTopBottom.js"></script>

<script src="/js/tools/lightDarkSwitch.js"></script>





    
<script src="/js/tools/codeBlock.js"></script>






    
<script src="/js/tools/runtime.js"></script>

    
<script src="/js/layouts/odometer.min.js"></script>

    
<link rel="stylesheet" href="/assets/odometer-theme-minimal.css">




  
<script src="/js/libs/Typed.min.js"></script>

  
<script src="/js/plugins/typed.js"></script>







<div class="post-scripts pjax">
    
        
<script src="/js/tools/tocToggle.js"></script>

<script src="/js/libs/anime.min.js"></script>

<script src="/js/layouts/toc.js"></script>

<script src="/js/plugins/tabs.js"></script>

    
</div>


    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax',
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            Global.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            Global.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            Global.refresh();
        });
    });
</script>




</body>
</html>
