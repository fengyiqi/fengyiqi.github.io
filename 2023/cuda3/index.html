<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="Hexo Theme Redefine">
    
    <meta name="author" content="YiQi">
    <!-- preconnect -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    
    
    <!--- Seo Part-->
    
    <link rel="canonical" href="http://fengyiqi.github.io/2023/cuda3/"/>
    <meta name="robots" content="index,follow">
    <meta name="googlebot" content="index,follow">
    <meta name="revisit-after" content="1 days">
    
        <meta property="og:type" content="article">
<meta property="og:title" content="CUDA编程03: 全局内存、共享内存以及原子函数的合理使用">
<meta property="og:url" content="http://fengyiqi.github.io/2023/cuda3/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://yiqiblogimages.oss-cn-hangzhou.aliyuncs.com/cuda/bank.png">
<meta property="og:image" content="https://yiqiblogimages.oss-cn-hangzhou.aliyuncs.com/cuda/bank_test.png">
<meta property="og:image" content="https://yiqiblogimages.oss-cn-hangzhou.aliyuncs.com/cuda/atomic_type.png">
<meta property="og:image" content="https://yiqiblogimages.oss-cn-hangzhou.aliyuncs.com/cuda/graphene.jpg">
<meta property="og:image" content="https://yiqiblogimages.oss-cn-hangzhou.aliyuncs.com/cuda/graphene_bond.jpg">
<meta property="article:published_time" content="2023-01-03T22:26:09.000Z">
<meta property="article:modified_time" content="2023-03-11T21:57:54.809Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="CUDA">
<meta property="article:tag" content="C">
<meta property="article:tag" content="C++">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yiqiblogimages.oss-cn-hangzhou.aliyuncs.com/cuda/bank.png">
    
    
    <!--- Icon Part-->
    <link rel="icon" type="image/png" href="/images/logo.svg" sizes="192x192">
    <link rel="apple-touch-icon" sizes="180x180" href="/images/logo.svg">
    <meta name="theme-color" content="#A31F34">
    <link rel="shortcut icon" href="/images/logo.svg">
    <!--- Page Info-->
    
    <title>
        
            CUDA编程03: 全局内存、共享内存以及原子函数的合理使用 -
        
        YiQi&#39;s Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    
<link rel="stylesheet" href="/assets/fonts.css">

    <!--- Font Part-->
    
    
    
    

    <!--- Inject Part-->
    
    <script id="hexo-configurations">
    let Global = window.Global || {};
    Global.hexo_config = {"hostname":"fengyiqi.github.io","root":"/","language":"zh-CN"};
    Global.theme_config = {"articles":{"style":{"font_size":"16px","line_height":1.5,"image_border_radius":"8px","image_alignment":"center","image_caption":false,"link_icon":true},"word_count":{"enable":true,"count":true,"min2read":true},"author_label":{"enable":true,"auto":false,"list":[]},"code_block":{"copy":true,"style":"simple","font":{"enable":false,"family":null,"url":null}},"toc":{"enable":true,"max_depth":3,"number":false,"expand":true,"init_open":true},"copyright":false,"lazyload":false,"recommendation":{"enable":false,"title":"推荐阅读","limit":3,"placeholder":"/images/wallhaven-wqery6-light.webp","skip_dirs":[]}},"colors":{"primary":"#A31F34","secondary":null},"global":{"fonts":{"chinese":{"enable":false,"family":null,"url":null},"english":{"enable":false,"family":null,"url":null}},"content_max_width":"1000px","sidebar_width":"210px","hover":{"shadow":true,"scale":false},"scroll_progress":{"bar":false,"percentage":true},"busuanzi_counter":{"enable":true,"site_pv":true,"site_uv":true,"post_pv":true},"pjax":true,"open_graph":true,"google_analytics":{"enable":false,"id":null}},"home_banner":{"enable":true,"style":"fixed","image":{"light":"https://yiqiblogimages.oss-cn-hangzhou.aliyuncs.com/home/geometry.jpg","dark":"https://yiqiblogimages.oss-cn-hangzhou.aliyuncs.com/home/night_sky.jpg"},"title":"早日毕业！","subtitle":{"text":["我们的征途是星辰大海"],"hitokoto":{"enable":true,"api":"https://v1.hitokoto.cn/?c=c&c=h&c=i&c=l"},"typing_speed":100,"backing_speed":80,"starting_delay":500,"backing_delay":1500,"loop":false,"smart_backspace":true},"text_color":{"light":"#404040","dark":"#e0e0e0"},"text_style":{"title_size":"2.8rem","subtitle_size":"1.5rem","line_height":1.2},"custom_font":{"enable":false,"family":null,"url":null},"social_links":{"enable":false,"links":{"github":"https://github.com/fengyiqi","instagram":null,"zhihu":null,"twitter":null,"email":"yiqi.feng@hotmail.com"}}},"plugins":{"feed":{"enable":false},"aplayer":{"enable":false,"type":"fixed","audios":[{"name":null,"artist":null,"url":null,"cover":null}]},"mermaid":{"enable":false,"version":"9.3.0"}},"version":"2.1.4","navbar":{"auto_hide":false,"color":{"left":"#404040","right":"#ffffff","transparency":30},"links":{"Home":{"path":"/","icon":"fa-regular fa-house"},"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"Categories":{"path":"/categories","icon":"fa-regular fa-list"},"About":{"path":"/about","icon":"fa-regular fa-face-grin-beam-sweat"}},"search":{"enable":false,"preload":true}},"page_templates":{"friends_column":2,"tags_style":"blur"},"home":{"sidebar":{"enable":true,"position":"left","first_item":"menu","announcement":null,"links":{"Archives":{"path":"/archives","icon":"fa-regular fa-archive"},"Categories":{"path":"/categories","icon":"fa-regular fa-list"},"About":{"path":"/about","icon":"fa-regular fa-face-grin-beam-sweat"}}},"article_date_format":"auto","categories":{"enable":true,"limit":3},"tags":{"enable":true,"limit":3}}};
    Global.language_ago = {"second":"%s 秒前","minute":"%s 分钟前","hour":"%s 小时前","day":"%s 天前","week":"%s 周前","month":"%s 个月前","year":"%s 年前"};
    Global.data_config = {"masonry":false};
  </script>
    
    <!--- Fontawesome Part-->
    
<link rel="stylesheet" href="/fontawesome/fontawesome.min.css">

    
<link rel="stylesheet" href="/fontawesome/brands.min.css">

    
<link rel="stylesheet" href="/fontawesome/solid.min.css">

    
<link rel="stylesheet" href="/fontawesome/regular.min.css">

    
    
    
    
<meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>


<body>
<div class="progress-bar-container">
    

    
        <span class="pjax-progress-bar"></span>
        <span class="pjax-progress-icon">
            <i class="fa-solid fa-circle-notch fa-spin"></i>
        </span>
    
</div>


<main class="page-container">

    

    <div class="main-content-container">

        <div class="main-content-header">
            <header class="navbar-container">
    
    <div class="navbar-content">
        <div class="left">
            
                <a class="logo-image" href="/">
                    <img src="/images/logo.svg">
                </a>
            
            <a class="logo-title" href="/">
                
                YiQi&#39;s Blog
                
            </a>
        </div>

        <div class="right">
            <!-- PC -->
            <div class="desktop">
                <ul class="navbar-list">
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/"  >
                                    
                                        
                                            <i class="fa-regular fa-house"></i>
                                        
                                        首页
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/archives"  >
                                    
                                        
                                            <i class="fa-regular fa-archive"></i>
                                        
                                        归档
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/categories"  >
                                    
                                        
                                            <i class="fa-regular fa-list"></i>
                                        
                                        分类
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                        
                            <li class="navbar-item">
                                <!-- Menu -->
                                <a class="" 
                                    href="/about"  >
                                    
                                        
                                            <i class="fa-regular fa-face-grin-beam-sweat"></i>
                                        
                                        关于
                                    
                                </a>
                                <!-- Submenu -->
                                
                            </li>
                    
                    
                </ul>
            </div>
            <!-- Mobile -->
            <div class="mobile">
                
                <div class="icon-item navbar-bar">
                    <div class="navbar-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <!-- Mobile drawer -->
    <div class="navbar-drawer">
        <ul class="drawer-navbar-list">
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="" 
                        href="/"  >
                             
                                
                                    <i class="fa-regular fa-house"></i>
                                
                                首页
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="" 
                        href="/archives"  >
                             
                                
                                    <i class="fa-regular fa-archive"></i>
                                
                                归档
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="" 
                        href="/categories"  >
                             
                                
                                    <i class="fa-regular fa-list"></i>
                                
                                分类
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            
                
                    <li class="drawer-navbar-item flex-center">
                        <a class="" 
                        href="/about"  >
                             
                                
                                    <i class="fa-regular fa-face-grin-beam-sweat"></i>
                                
                                关于
                            
                        </a>
                    </li>
                    <!-- Submenu -->
                    
            

        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="main-content-body">

            

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="post-page-container">
        <div class="article-content-container">

            
            
                <div class="article-title">
                    <h1 class="article-title-regular">CUDA编程03: 全局内存、共享内存以及原子函数的合理使用</h1>
                </div>
            
                
            

            
                <div class="article-header">
                    <div class="avatar">
                        <img src="/images/logo.svg">
                    </div>
                    <div class="info">
                        <div class="author">
                            <span class="name">YiQi</span>
                            
                                <span class="author-label">Lv3</span>
                            
                        </div>
                        <div class="meta-info">
                            <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fa-regular fa-pen-fancy"></i>&nbsp;
        <span class="desktop">2023-01-03 23:26:09</span>
        <span class="mobile">2023-01-03 23:26</span>
        <span class="hover-info">创建</span>
    </span>
    
        <span class="article-date article-meta-item">
            <i class="fa-regular fa-wrench"></i>&nbsp;
            <span class="desktop">2023-03-11 22:57:54</span>
            <span class="mobile">2023-03-11 22:57</span>
            <span class="hover-info">更新</span>
        </span>
    

    
        <span class="article-categories article-meta-item">
            <i class="fa-regular fa-folders"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/categories/CUDA/">CUDA</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fa-regular fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/CUDA/">CUDA</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/C/">C</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/C/">C++</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fa-regular fa-typewriter"></i>&nbsp;<span>5.4k 字</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fa-regular fa-clock"></i>&nbsp;<span>21 分钟</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fa-regular fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                        </div>
                    </div>
                </div>
            

            <div class="article-content markdown-body">
                <h2 id="全局内存的合理使用"><a href="#全局内存的合理使用" class="headerlink" title="全局内存的合理使用"></a>全局内存的合理使用</h2><p>在启用了L1缓存的情况下,对全局内存的读取将首先尝试经过L1缓存；如果未命中，则接着尝试经过L2缓存；如果再次未命中，则直接从DRAM读取。—次数据传输处理的数据量在默认情况下是32字节。</p>
<h3 id="全局内存的合并与非合并访问"><a href="#全局内存的合并与非合并访问" class="headerlink" title="全局内存的合并与非合并访问"></a>全局内存的合并与非合并访问</h3><p>合并（coalesced）访问指的是一个线程束对全局内存的一次访问请求（读或者写）导致最少数量的数据传输，否则称访问是非合并的（uncoalesced）。</p>
<p>合并度（degree of coalescing）它等于线程束请求的字节数除以由该请求导致的所有数据传输处理的字节数。合并访问对应合并度100%</p>
<blockquote>
<p>以下讨论忽略L1缓存，即全局内存 –&gt; L2缓存 –&gt; SM，一次将传输32字节数据。</p>
</blockquote>
<p>数据传输对数据地址的要求:在一次数据传输中，从全局内存转移到L2缓存的一片内存的首地址一定是一个最小粒度（这里是32字节）的整数倍。例如，一次数据传输只能从全局内存读取地址为0～31字节、32～63字节、64～95字节、96～127字节等片段的数据。</p>
<p>使用CUDA运行时API函数（如我们常用的<code>cudaMalloc</code>）分配的内存的首地址至少是256字节的整数倍。</p>
<ol>
<li>顺序的合并访问： <div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> __global__ <span class="title">add</span><span class="params">(<span class="type">float</span> *x, <span class="type">float</span> *y, <span class="type">float</span> *z)</span> </span>{</span><br><span class="line">    <span class="type">int</span> n = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    z[n] = x[n] + y[n];</span><br><span class="line">}</span><br><span class="line">add&lt;&lt;&lt;<span class="number">128</span>, <span class="number">32</span>&gt;&gt;&gt;(x, y, z);</span><br></pre></td></tr></table></figure></div>
 <code>x</code>, <code>y</code>和<code>z</code>是由<code>cudaMalloc</code>分配的全局内存的指针。很容易看出,核函数中对这几个指针所指内存区域的访问都是合并的。例如，第—个线程块中的线程束将访问数组<code>x</code>中第0-31个元素，对应128字节的连续内存，而且首地址一定是256字节的整数倍。这样的访问只需要4次数据传输即可完成。所以是合并访问，合并度为100％。</li>
<li>乱序的合并访问： <div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> __global__ <span class="title">add_permuted</span><span class="params">(<span class="type">float</span> *x, <span class="type">float</span> *y, <span class="type">float</span> *z)</span> </span>{</span><br><span class="line">    <span class="type">int</span> tid_permuted = threadIdx.x ^ <span class="number">0x1</span>;</span><br><span class="line">    <span class="type">int</span> n = tid_permuted + blockIdx.x * blockDim.x;</span><br><span class="line">    z[n] = x[n] + y[n];</span><br><span class="line">}</span><br><span class="line">add_permuted&lt;&lt;&lt;<span class="number">128</span>, <span class="number">32</span>&gt;&gt;&gt;(x, y, z);</span><br></pre></td></tr></table></figure></div>
 其中，<code>threadIdx.x ^ 0x1</code>是某种置换操作，作用是将0～31的整数做某种置换（交换两个相邻的数）。第一个线程块中的线程束将依然访问数组<code>x</code>中第0～31个元素，只不过线程号与数组元素指标不完全—致而已。这样的访问是乱序的（或者交叉的）合并访问，合并度也为100％。</li>
<li>不对齐的非合并访问 <div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> __global__ <span class="title">add_offset</span><span class="params">(<span class="type">float</span> *x, <span class="type">float</span> *y, <span class="type">float</span> *z)</span> </span>{</span><br><span class="line">    <span class="type">int</span> n = threadIdx.x + blockIdx.x * blockDim.x + <span class="number">1</span>;</span><br><span class="line">    z[n] = x[n] + y[n];</span><br><span class="line">}</span><br><span class="line">add_offset&lt;&lt;&lt;<span class="number">128</span>, <span class="number">32</span>&gt;&gt;&gt;(x, y, z);</span><br></pre></td></tr></table></figure></div>
 地址偏置了一位，所以将触发5次数据传输，合并度为4/5 * 100% = 80%</li>
<li>跨越式的非合并访问 <div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> __global__ <span class="title">add_stride</span><span class="params">(<span class="type">float</span> *x, <span class="type">float</span> *y, <span class="type">float</span> *z)</span> </span>{</span><br><span class="line">    <span class="comment">// 注意这里n的表达式与前面的都不一样</span></span><br><span class="line">    <span class="type">int</span> n = blockIdx.x + threadIdx.x * gridDim.x;</span><br><span class="line">    z[n] = x[n] + y[n];</span><br><span class="line">}</span><br><span class="line">add_stride&lt;&lt;&lt;<span class="number">128</span>, <span class="number">32</span>&gt;&gt;&gt;(x, y, z);</span><br></pre></td></tr></table></figure></div>
 第—个线程块中的线程束将访问数组<code>x</code>中指标为0, 128, 256, 384等的元素。将触发32次数据传输，属于跨越式非合并访问，合并度为4/32*100%=12.5%</li>
<li>广播式的非合并访问 <div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> __global__ <span class="title">add_broadcast</span><span class="params">(<span class="type">float</span> *x, <span class="type">float</span> *y, <span class="type">float</span> *z)</span> </span>{</span><br><span class="line">    <span class="type">int</span> n = threadIdx.x + blockIdx.x * blockDim.x;</span><br><span class="line">    z[n] = x[<span class="number">0</span>] + y[n]; </span><br><span class="line">}</span><br><span class="line">add_broadcast&lt;&lt;&lt;<span class="number">128</span>, <span class="number">32</span>&gt;&gt;&gt;(x, y, z);</span><br></pre></td></tr></table></figure></div>
 第一个线程块中的线程束将一致地访问数组<code>x</code>中的第0个元素。这只需要一次数据传输（处理32字节的数据），但由于整个线程束只使用了4字节的数据，故合并度为4/32×100％=12.5％.这样的访问属于广播式的非合并访问。这样的访问（如果是读数据的话）适合采用第6章提到的常量内存。</li>
</ol>
<h3 id="例子：矩阵转置"><a href="#例子：矩阵转置" class="headerlink" title="例子：矩阵转置"></a>例子：矩阵转置</h3><p>完整代码见 <a class="link" target="_blank" rel="noopener" href="https://github.com/fengyiqi/cppCUDA/blob/master/tutorials/matrix.cu">matrix.cu <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>，这里只列出第一种转置函数：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">transpose1</span><span class="params">(<span class="type">const</span> real *A, real *B, <span class="type">const</span> <span class="type">int</span> N)</span> </span>{</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> nx = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> ny = blockIdx.y * blockDim.y + threadIdx.y;</span><br><span class="line">    <span class="keyword">if</span> (nx &lt; N &amp;&amp; ny &lt; N) {</span><br><span class="line">        B[nx * N + ny] = A[ny * N + nx];</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<p>矩阵转置需要读写一块内存，比如<code>A</code>为原矩阵（读），<code>B</code>为转置后的矩阵（写），两者只能有一个是合并访问，另一个必是非合并访问。比如上面的函数<code>transpose1()</code>，对<code>A</code>的访问是合并的，对<code>B</code>的写入是非合并的。</p>
<p>在这种情况下，帕斯卡架构及之后的GPU，将读取操作写成非合并的，写入操作写成合并的，会比另一种方式速度快。这主要是因为编译器能够判断一个全局内存变量在整个核函数的范围都只可读（如这里的矩阵<code>A</code>），则会自动用函数<code>__ldg()</code>读取全局内存，从而缓存数据，缓解非合并带来的影响。</p>
<p>所以，在不能满足读取和写入都是合并的情况下，一般来说应当尽量做到合并地写入。</p>
<p>在本人的机器上测试，结果如下：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">transpose with coalesced read:</span><br><span class="line">Time = 7.32024 +- 0.531792 ms.</span><br><span class="line"></span><br><span class="line">transpose with coalesced write:</span><br><span class="line">Time = 4.16075 +- 0.301832 ms.</span><br><span class="line"></span><br><span class="line">transpose with coalesced write and __ldg read:</span><br><span class="line">Time = 4.20045 +- 0.248738 ms.</span><br></pre></td></tr></table></figure></div>

<h2 id="共享内存的合理使用"><a href="#共享内存的合理使用" class="headerlink" title="共享内存的合理使用"></a>共享内存的合理使用</h2><p>共享内存是一种可被程序员直接操控的缓存，主要作用有两个:</p>
<ul>
<li>一个是减少核函数中对全局内存的访问次数，实现高效的线程块内部的通信;</li>
<li>另一个是提高全局内存访问的合并度。</li>
</ul>
<h3 id="例子：数组归约计算"><a href="#例子：数组归约计算" class="headerlink" title="例子：数组归约计算"></a>例子：数组归约计算</h3><p>考虑如下简单地对数组求和的函数：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">real <span class="title">reduce</span><span class="params">(<span class="type">const</span> real *x, <span class="type">const</span> <span class="type">int</span> N)</span> </span>{</span><br><span class="line">    real sum = <span class="number">0.0</span>;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; i++) {</span><br><span class="line">        sum += x[i];</span><br><span class="line">    }</span><br><span class="line">    <span class="keyword">return</span> sum;</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>
<p>考虑一个长度为10<sup>8</sup>的数组，每个元素都是1.23，使用双精度，计算结果为</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sum = 123000000.110771</span><br></pre></td></tr></table></figure></div>
<p>该结果前9位有效数字都正确，从第10位开始有错误。在使用单精度浮点数时，</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sum = 33554432.000000</span><br></pre></td></tr></table></figure></div>
<p>结果完全错误。这是因为，在累加计算中出现了所谓的“大数吃小数”的现象。单精度浮点数只有6、7位精确的有效数字。在上面的函数<code>reduce()</code>中，将变量<code>sum</code>的值累加到3000多万后，再将它和1.23相加，其值就不再增加了（小数被大数“吃掉了”但大数并没有变化）。现在已经发展出更加安全的求和算法，如Kahan求和算法，但这里不讨论。后面会看到，基于CUDA的实现要比上述C＋＋实现稳健（robust）得多，使用单精度浮点数时结果也相当准确。</p>
<h4 id="仅使用全局内存"><a href="#仅使用全局内存" class="headerlink" title="仅使用全局内存"></a>仅使用全局内存</h4><p>假设数组元素个数是2的整数次方（这个假设可以轻易去掉），我们可以将数组后半部分的各个元素与前半部分对应的数组元素相加。如果重复此过程，最后得到的第一个数组元素就是最初的数组中各个元素的和。这就是所谓的折半归约（binary reduction）法。</p>
<p>以下为轻易能想到的错误代码：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> __global__ <span class="title">reduce</span><span class="params">(real *d_x, <span class="type">int</span> N)</span> </span>{</span><br><span class="line">    <span class="type">int</span> n = blockDim.x * blockIdx.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = N / <span class="number">2</span>; offset &gt; <span class="number">0</span>; offset /= <span class="number">2</span>) {</span><br><span class="line">        <span class="keyword">if</span> (n &lt; offset) { d_x[n] += d_x[n + offset]; }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>
<p>以上代码问题在于无法保证<code>d_x</code>各个数位的元素被处理的顺序。</p>
<p>可以使用<code>__syncthreads()</code>进行同步。<code>__syncthreads()</code>只同步一个线程块中的所有进程，那么我们就利用该功能让每个线程块对其中的数组元素进行归约。函数代码如下：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> __global__ <span class="title">reduce_global</span><span class="params">(real *d_x, real *d_y)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    real *x = d_x + blockDim.x * blockIdx.x;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = blockDim.x &gt;&gt; <span class="number">1</span>; offset &gt; <span class="number">0</span>; offset &gt;&gt;= <span class="number">1</span>) {</span><br><span class="line">        <span class="keyword">if</span> (tid &lt; offset) {</span><br><span class="line">            x[tid] += x[tid + offset];</span><br><span class="line">        }</span><br><span class="line">        __syncthreads();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>) {</span><br><span class="line">        d_y[blockIdx.x] = x[<span class="number">0</span>];</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>
<ul>
<li><code>x</code>在不同的线程块中指向全局内存中不同的地址</li>
<li>我们这里不再假设<code>N</code>是2的整数次方，但假设<code>N</code>能够被<code>blockDim.x</code>整除，而且假设<code>blockDim.x</code>是2的整数次方（作者采用最常用的线程块大小128）</li>
<li>这里我们将<code>blockDim.x / 2</code>写成了<code>blockDim.x &gt;&gt; 1</code>，并将<code>offset /= 2</code>写成了<code>offset &gt;&gt;= 1</code>，这是利用了位操作</li>
<li>该核函数仅仅将—个长度为10<sup>8</sup>的数组<code>d_x</code>归约到一个长度为10<sup>8</sup> / 128的数组<code>d_y</code>。为了计算整个数组元素的和，我们将数组<code>d_y</code>从设备复制到主机，并在主机继续对数组<code>d_y</code>归约，得到最终的结果。这样做不是很高效，但我们暂时先这样做。</li>
</ul>
<h4 id="使用共享内存"><a href="#使用共享内存" class="headerlink" title="使用共享内存"></a>使用共享内存</h4><p>在核函数中,要将一个变量定义为共享内存变量，就要在定义语句中加上一个限定符<code>__shared__</code>，比如：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__shared__ real s_y[<span class="number">128</span>];</span><br></pre></td></tr></table></figure></div>
<ul>
<li>在一个核函数中定义一个共享内存变量，就相当于在每一个线程块中有了一个该变量的副本。</li>
<li>每个副本都不一样，虽然它们共用一个变量名。</li>
<li>核函数中对共享内存变量的操作都是同时作用在所有的副本上的。</li>
</ul>
<p>基于共享内存，可以定义归约函数为：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> __global__ <span class="title">reduce_shared</span><span class="params">(real *d_x, real *d_y)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> bid = blockIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> n = bid * blockDim.x + tid;</span><br><span class="line">    __shared__ real s_y[<span class="number">128</span>];</span><br><span class="line">    s_y[tid] = (n &lt; N) ? d_x[n] : <span class="number">0.0</span>;</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = blockDim.x &gt;&gt; <span class="number">1</span>; offset &gt; <span class="number">0</span>; offset &gt;&gt;= <span class="number">1</span>) {</span><br><span class="line">        <span class="keyword">if</span> (tid &lt; offset) {</span><br><span class="line">            s_y[tid] += s_y[tid + offset];</span><br><span class="line">        }</span><br><span class="line">        __syncthreads();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>) {</span><br><span class="line">        d_y[bid] = s_y[<span class="number">0</span>];</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>
<ul>
<li>第8行的<code>__syncthreads()</code>用以确保共享内存变量中的数据对线程块内的所有线程来说都准备就绪。</li>
<li>共享内存生命周期仅在核函数内，所以在核函数结束之前需要将共享内存中的某些结果保存到全局内存中。</li>
</ul>
<p>一般来说，在核函数中对共享内存访问的次数越多，则由使用共享内存带来的加速效果越明显。本例使用共享内存加速效果有限，但相比于仅使用全局内存还有两个好处：</p>
<ul>
<li>一个是不再要求全局内存数组的长度N是线程块大小的整数倍</li>
<li>另一个是在归约的过程中不会改变全局内存数组中的数据</li>
</ul>
<p>共享内存的另一个作用是改善全局内存的访问方式（将非合并的全局内存访问转化为合并的），本例并未涉及。</p>
<h4 id="使用动态共享内存"><a href="#使用动态共享内存" class="headerlink" title="使用动态共享内存"></a>使用动态共享内存</h4><p>如果在定义共享内存时把数组长度写错了，就有可能引起错误或者降低核函数性能。使用动态共享内存可以减少这种错误发生的概率。 </p>
<p>要使用共享内存，首先在调用核函数时写下第三个参数</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;&lt;&lt;grid_size, block_size, <span class="built_in">sizeof</span>(real) * blocksize&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></div>
<p>其次，在核函数中：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> __shared__ real s_y[];</span><br></pre></td></tr></table></figure></div>
<blockquote>
<p>这里不能使用<code>extern __shared__ real *s_y</code>，数组不等价于指针</p>
</blockquote>
<p>使用动态共享内存和使用静态共享内存在执行时间上几乎无差别，但可以提高程序的可维护性。</p>
<h4 id="使用共享内存处理转置"><a href="#使用共享内存处理转置" class="headerlink" title="使用共享内存处理转置"></a>使用共享内存处理转置</h4><h5 id="有bank冲突"><a href="#有bank冲突" class="headerlink" title="有bank冲突"></a>有bank冲突</h5><p>基于共享内存，可以对<code>transpose1()</code>函数优化：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">__global__ <span class="type">void</span> <span class="title">transpose1</span><span class="params">(<span class="type">const</span> real *A, real *B, <span class="type">const</span> <span class="type">int</span> N)</span> </span>{</span><br><span class="line">    __shared__ real S[TILE_DIM][TILE_DIM];</span><br><span class="line">    <span class="type">int</span> bx = blockIdx.x * TILE_DIM;</span><br><span class="line">    <span class="type">int</span> by = blockIdx.y * TILE_DIM;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> nx1 = bx + threadIdx.x;</span><br><span class="line">    <span class="type">int</span> ny1 = by + threadIdx.y;</span><br><span class="line">    <span class="keyword">if</span> (nx1 &lt; N &amp;&amp; ny1 &lt; N) {</span><br><span class="line">        S[threadIdx.y][threadIdx.x] = A[ny1 * N + nx1];</span><br><span class="line">    }</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> nx2 = bx + threadIdx.y;</span><br><span class="line">    <span class="type">int</span> ny2 = by + threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span> (nx2 &lt; N &amp;&amp; ny2 &lt; N) {</span><br><span class="line">        B[nx2 * N + ny2] = S[threadIdx.x][threadIdx.y];</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>

<ul>
<li>对<code>A</code>的读取是合并的，这很容易看出来</li>
<li>对<code>B</code>来说，写入也是合并的（可以想象成，也是按照x方向先遍历，但是将<code>S</code>的x, y反转了）</li>
</ul>
<p>在本人机器上测试结果：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">transpose with shared memory bank conflict:</span><br><span class="line">Time = 5.5485 +- 0.328543 ms.</span><br></pre></td></tr></table></figure></div>
<p>比最初的<code>transpose1()</code>要快。</p>
<h5 id="无bank冲突"><a href="#无bank冲突" class="headerlink" title="无bank冲突"></a>无bank冲突</h5><p>为了获得高的内存带宽，共享内存在物理上被分为32个（刚好等于一个线程束中的线程数目，即内建变量<code>warpSize</code>的值）同样宽度的、能被同时访问的内存bank。在除开普勒架构外，每个bank的宽度为4字节。共享内存数组中连续的128字节的内容分摊到32个bank的某—层中，每个bank负责4字节的内容。</p>
<p>只要同一线程束内的多个线程不同时访问同一个bank中不同层的数据,该线程束对共享内存的访问就只需要一次内存事务（memory transaction）。当同一线程束内的多个线程试图访问同一个bank中不同层的数据时，就会发生bank冲突。</p>
<p>在核函数<code>tranpose1()</code>中定义了一个长度为32 * 32 = 1024的单精度浮点型变量的共享内存数组，其排列方式如下图所示</p>
<p align="center">
    <img src="https://yiqiblogimages.oss-cn-hangzhou.aliyuncs.com/cuda/bank.png">
</p>

<p>核函数<code>tranpose1()</code>的第16行代码，同一个线程束中的32个线程（连续的32个<code>threadIdx.x</code>值）将对应共享内存数组<code>S</code>中跨度为32的数据。也就是说，这32个线程将刚好访问同一个bank中的32个数据，这将导致32路bank冲突。相比之下，核函数<code>tranpose1()</code>的第9行代码就不会发生bank冲突。</p>
<p>通常可以用改变共享内存数组大小的方式来消除或减轻共享内存的bank冲突。例如，将上述核函数中的共享内存定义修改如下:</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">__shared__ real S[TILE_DIM][TILE_DIM + <span class="number">1</span>];</span><br></pre></td></tr></table></figure></div>
<p>就可以完全消除第16行读取共享内存时的bank冲突。</p>
<blockquote>
<p>这里有点不好理解，可以尝试这种思路：二维数组的第二行第一列数据被放在了0132这个位置，0128位置上没有有效数据，那么读取第二行第一列数据时，其实读取的是bank<sub>1</sub>第二层内存数据。</p>
</blockquote>
<p>在本人机器上测试结果：</p>
<div class="highlight-container" data-rel="Plaintext"><figure class="iseeu highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">transpose without shared memory bank conflict:</span><br><span class="line">Time = 3.51271 +- 0.426474 ms.</span><br></pre></td></tr></table></figure></div>

<p>作者测试的结果：</p>
<p align="center">
    <img src="https://yiqiblogimages.oss-cn-hangzhou.aliyuncs.com/cuda/bank_test.png">
</p>

<h2 id="原子函数的合理使用"><a href="#原子函数的合理使用" class="headerlink" title="原子函数的合理使用"></a>原子函数的合理使用</h2><p>考虑前面数组归约的代码：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> __global__ <span class="title">reduce_shared</span><span class="params">(real *d_x, real *d_y)</span></span></span><br><span class="line"><span class="function"></span>{</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> tid = threadIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> bid = blockIdx.x;</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> n = bid * blockDim.x + tid;</span><br><span class="line">    __shared__ real s_y[<span class="number">128</span>];</span><br><span class="line">    s_y[tid] = (n &lt; N) ? d_x[n] : <span class="number">0.0</span>;</span><br><span class="line">    __syncthreads();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> offset = blockDim.x &gt;&gt; <span class="number">1</span>; offset &gt; <span class="number">0</span>; offset &gt;&gt;= <span class="number">1</span>) {</span><br><span class="line">        <span class="keyword">if</span> (tid &lt; offset) {</span><br><span class="line">            s_y[tid] += s_y[tid + offset];</span><br><span class="line">        }</span><br><span class="line">        __syncthreads();</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (tid == <span class="number">0</span>) {</span><br><span class="line">        d_y[bid] = s_y[<span class="number">0</span>];</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>
<p>如果将最后三行代码改成：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (tid == <span class="number">0</span>) {</span><br><span class="line">    d_y[<span class="number">0</span>] = s_y[<span class="number">0</span>];</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>
<p>就得不到正确结果，因为线程块之间没有同步，两个线程块可能同时读取<code>d_y[0]</code>。为了克服这个问题，可以才用原子函数：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (tid == <span class="number">0</span>) {</span><br><span class="line">    <span class="built_in">atomicAdd</span>(&amp;d_y[<span class="number">0</span>], s_y[<span class="number">0</span>]);</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>
<p><code>atomicAdd(adress, value)</code>第一个参数是待累加变量的地址，第二个参数是累加的值。该函数的作用是先将地址<code>address</code>中旧值<code>old</code>读出，计算<code>old + val</code>，然后将计算的值存入地址<code>address</code>。原子函数不能保证各个线程的执行具有特定的次序,但是能够保证每个线程的操作一气呵成，不被其他线程干扰，所以能够保证得到正确的结果。完整代码见 <a class="link" target="_blank" rel="noopener" href="https://github.com/fengyiqi/cppCUDA/blob/master/tutorials/reduceGPU_atomic.cu">reduceGPU_atomic.cu <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a></p>
<h3 id="原子函数"><a href="#原子函数" class="headerlink" title="原子函数"></a>原子函数</h3><p>原子函数第一个参数可以指向全局内存，也可以指问共享内存。对所有参与的线程来说，该“读-改-写”的原子操作是一个线程一个线程轮流做的，但没有明确的次序。另外，原子函数没有同步功能。</p>
<p>从帕斯卡架构开始，在原来的原子函数的基础上引入了两类新的原子函数。例如，对原子函数<code>atomicAdd()</code>来说，从帕斯卡架构起引入了另外两个原子函数，分别是<code>atomicAdd_system</code>和<code>atomicAdd_block()</code>，前者将原子函数的作用范围扩展到整个同节点的异构系统（包括主机和所有设备），后者将原子函数的作用范围缩小至一个线程块。<strong>原子函数的返回值是<code>old</code></strong></p>
<ul>
<li>加法：<code>T atomicAdd(T *adress, T val);</code><br>  功能：<code>new = old + val</code></li>
<li>减法：<code>T atomicSub(T *adress, T val);</code><br>  功能：<code>new = old - val</code></li>
<li>交换：<code>T atomicExch(T *adress, T val);</code><br>  功能：<code>new = val</code></li>
<li>最小值：<code>T atomicMin(T *adress, T val);</code><br>  功能：<code>new = (old &lt; val) ? old : val</code></li>
<li>最大值：<code>T atomicMax(T *adress, T val);</code><br>  功能：<code>new = (old &gt; val) ? old : val</code></li>
<li>自增：<code>T atomicInc(T *adress, T val);</code><br>  功能：<code>new = (old &gt;= val) ? 0 : (old + 1)</code></li>
<li>自减：<code>T atomicDec(T *adress, T val);</code><br>  功能：<code>new = ((old == 0) || (old &gt; val)) ? val : (old - 1)</code></li>
<li>比较-交换：<code>T atomicCAS(T *adress, T compare, T val);</code><br>  功能：<code>new = (old == compare) ? val : old</code></li>
<li>按位与：<code>T atomicAnd(T *adress, T val);</code><br>  功能：<code>new = old &amp; val</code></li>
<li>按位或：<code>T atomicOr(T *adress, T val);</code><br>  功能：<code>new = old | val</code></li>
<li>按位异与：<code>T atomicXor(T *adress, T val);</code><br>  功能：<code>new = old ^ val</code></li>
</ul>
<p align="center">
    <img src="https://yiqiblogimages.oss-cn-hangzhou.aliyuncs.com/cuda/atomic_type.png">
</p>

<h3 id="例子：邻居列表的建立"><a href="#例子：邻居列表的建立" class="headerlink" title="例子：邻居列表的建立"></a>例子：邻居列表的建立</h3><p>两个粒子互为邻居的判据如下：它们的距离不大于一个给定的截断距离r<sub>c</sub>。</p>
<p>我们的基本算法如下：对每一个给定的粒子，通过比较它与所有其他粒子的距离来判断相应的粒子对是否互为邻居。</p>
<p>这是一个计算量正比于粒子数平方N<sup>2</sup>的算法，或者<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="6.681ex" height="2.452ex" role="img" focusable="false" viewBox="0 -833.9 2952.8 1083.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="4F" d="M308 428Q289 428 289 438Q289 457 318 508T378 593Q417 638 475 671T599 705Q688 705 732 643T777 483Q777 380 733 285T620 123T464 18T293 -22Q188 -22 123 51T58 245Q58 327 87 403T159 533T249 626T333 685T388 705Q404 705 404 693Q404 674 363 649Q333 632 304 606T239 537T181 429T158 290Q158 179 214 114T364 48Q489 48 583 165T677 438Q677 473 670 505T648 568T601 617T528 636Q518 636 513 635Q486 629 460 600T419 544T392 490Q383 470 372 459Q341 430 308 428Z"></path></g></g><g data-mml-node="mo" transform="translate(796,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msup" transform="translate(1185,0)"><g data-mml-node="mi"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g><g data-mml-node="mn" transform="translate(975.3,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(2563.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>算法。对于大体系，有一个更加高效但编程实现相对复杂的<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="5.57ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 2462 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="4F" d="M308 428Q289 428 289 438Q289 457 318 508T378 593Q417 638 475 671T599 705Q688 705 732 643T777 483Q777 380 733 285T620 123T464 18T293 -22Q188 -22 123 51T58 245Q58 327 87 403T159 533T249 626T333 685T388 705Q404 705 404 693Q404 674 363 649Q333 632 304 606T239 537T181 429T158 290Q158 179 214 114T364 48Q489 48 583 165T677 438Q677 473 670 505T648 568T601 617T528 636Q518 636 513 635Q486 629 460 600T419 544T392 490Q383 470 372 459Q341 430 308 428Z"></path></g></g><g data-mml-node="mo" transform="translate(796,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1185,0)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g><g data-mml-node="mo" transform="translate(2073,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>算法，计算量仅仅正比于粒子数N，但为简单起见，这里不讨论<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="5.57ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 2462 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="4F" d="M308 428Q289 428 289 438Q289 457 318 508T378 593Q417 638 475 671T599 705Q688 705 732 643T777 483Q777 380 733 285T620 123T464 18T293 -22Q188 -22 123 51T58 245Q58 327 87 403T159 533T249 626T333 685T388 705Q404 705 404 693Q404 674 363 649Q333 632 304 606T239 537T181 429T158 290Q158 179 214 114T364 48Q489 48 583 165T677 438Q677 473 670 505T648 568T601 617T528 636Q518 636 513 635Q486 629 460 600T419 544T392 490Q383 470 372 459Q341 430 308 428Z"></path></g></g><g data-mml-node="mo" transform="translate(796,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1185,0)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g><g data-mml-node="mo" transform="translate(2073,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>算法。</p>
<p>原子排列如下图所示：</p>
<p align="center">
    <img src="https://yiqiblogimages.oss-cn-hangzhou.aliyuncs.com/cuda/graphene.jpg">
</p>


<h4 id="C-版本："><a href="#C-版本：" class="headerlink" title="C++版本："></a>C++版本：</h4><p>源代码见 <a class="link" target="_blank" rel="noopener" href="https://github.com/fengyiqi/cppCUDA/blob/master/tutorials/neighborCPU.cu">neighborCPU.cu <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>。寻找邻居的函数如下：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> <span class="title">find_neighbor</span><span class="params">(<span class="type">int</span> *NN, <span class="type">int</span> *NL, <span class="type">const</span> real* x, <span class="type">const</span> real* y)</span> </span>{</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> n = <span class="number">0</span>; n &lt; N; n++) {</span><br><span class="line">        NN[n] = <span class="number">0</span>;</span><br><span class="line">    }</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> n1 = <span class="number">0</span>; n1 &lt; N; ++n1) {</span><br><span class="line">        real x1 = x[n1];</span><br><span class="line">        real y1 = y[n1];</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> n2 = n1 + <span class="number">1</span>; n2 &lt; N; ++n2) {</span><br><span class="line">            real x12 = x[n2] - x1;</span><br><span class="line">            real y12 = y[n2] - y1;</span><br><span class="line">            real distance_square = x12 * x12 + y12 * y12;</span><br><span class="line">            <span class="keyword">if</span> (distance_square &lt; cutoff_square) {</span><br><span class="line">                NL[n1 * MN + NN[n1]++] = n2;</span><br><span class="line">                NL[n2 * MN + NN[n2]++] = n1;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>
<ul>
<li>总原子数<code>N</code></li>
<li>每个原子最多有<code>MN</code>个邻居，这里设为10</li>
<li><code>cutoff_square</code>取1.9<sup>2</sup></li>
<li><code>NN[n]</code>是第<code>n</code>个原子的邻居个数</li>
<li><code>NL</code>长度为<code>N * MN</code>，其中<code>NL[n * MN + k]</code>是第<code>n</code>个粒子的第<code>k</code>个邻居</li>
<li><code>x</code>和<code>y</code>对应坐标</li>
</ul>
<p>最后用Python的matplotlib库画出了碳碳键，脚本见 <a class="link" target="_blank" rel="noopener" href="https://github.com/fengyiqi/cppCUDA/blob/master/tutorials/plot_graphene_bond.py">plot_graphene_bond.py <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>，图如下：</p>
<p align="center">
    <img src="https://yiqiblogimages.oss-cn-hangzhou.aliyuncs.com/cuda/graphene_bond.jpg">
</p>

<p>在本人机器上测试，每次运行时间大概在187ms左右（单精度）。</p>
<h4 id="利用原子操作的CUDA版本"><a href="#利用原子操作的CUDA版本" class="headerlink" title="利用原子操作的CUDA版本"></a>利用原子操作的CUDA版本</h4><p>从C++修改到CUDA版本，一般首先</p>
<ul>
<li>将线程指标<code>blockIdx.x * blockDim.x + threadIdx.x</code>对应到原子指标<code>n1</code>，去掉循环而改为判断<code>if (n &lt; N)</code>，</li>
<li>再修改对<code>n2</code>的循环。</li>
</ul>
<p>注意不要直接写成：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">d_NL[n1 * MN + d_NN[n1]++] = n2;</span><br><span class="line">d_NL[n2 * MN + d_NN[n2]++] = n1;</span><br></pre></td></tr></table></figure></div>
<p>在与<code>n1</code>对应的线程中，第二条语句代表我们试图对<code>d_NN[n2]</code>进行累加操作。但是，在与<code>n2</code>对应的线程中，第—条语句代表我们也试图对<code>d_NN[n2]</code>进行累加操作，这是不对的。这里应该是原子操作</p>
<p>正确函数应该是：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> __global__ <span class="title">find_neighbor_atomic</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">int</span> *d_NN, <span class="type">int</span> *d_NL, <span class="type">const</span> real *d_x, <span class="type">const</span> real *d_y, <span class="type">const</span> <span class="type">int</span> N, <span class="type">const</span> real cutoff_square</span></span></span><br><span class="line"><span class="params"><span class="function">)</span> </span>{</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> n1 = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span> (n1 &lt; N) {</span><br><span class="line">        d_NN[n1] = <span class="number">0</span>;</span><br><span class="line">        <span class="type">const</span> real x1 = d_x[n1];</span><br><span class="line">        <span class="type">const</span> real y1 = d_y[n1];</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> n2 = n1 + <span class="number">1</span>; n2 &lt; N; ++n2) {</span><br><span class="line">            <span class="type">const</span> real x12 = d_x[n2] - x1;</span><br><span class="line">            <span class="type">const</span> real y12 = d_y[n2] - y1;</span><br><span class="line">            <span class="type">const</span> real distance_square = x12 * x12 + y12 * y12;</span><br><span class="line">            <span class="keyword">if</span> (distance_square &lt; cutoff_square) {</span><br><span class="line">                d_NL[n1 * MN + <span class="built_in">atomicAdd</span>(&amp;d_NN[n1], <span class="number">1</span>)] = n2;</span><br><span class="line">                d_NL[n2 * MN + <span class="built_in">atomicAdd</span>(&amp;d_NN[n2], <span class="number">1</span>)] = n1;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">    }</span><br><span class="line">}</span><br></pre></td></tr></table></figure></div>
<p>还需要注意，将原子操作的代码改写成如下形式：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">d_NL[n1 * MN + d_NN[n1]] = n2;</span><br><span class="line"><span class="built_in">atomicAdd</span>(&amp;d_NN[n1], <span class="number">1</span>);</span><br><span class="line">d_NL[n2 * MN + d_NN[n2]] = n1;</span><br><span class="line"><span class="built_in">atomicAdd</span>(&amp;d_NN[n2], <span class="number">1</span>);</span><br></pre></td></tr></table></figure></div>
<p>是错误的，因为不能保证第二行的原子函数读取的<code>d_NN[n1]</code>有没有被别的线程的原子函数改动过。</p>
<h4 id="不用原子操作的CUDA版本"><a href="#不用原子操作的CUDA版本" class="headerlink" title="不用原子操作的CUDA版本"></a>不用原子操作的CUDA版本</h4><p>原子操作会降低并行度。有时可通过改变算法，避免原子操作。对于上面的问题，之所以使用原子操作，是因为不同的线程可能同时写入同一个全局内存地址，从而节省了一般的计算量。如果不节省另一半的计算量，就可以避免使用原子函数。</p>
<p>修改后的程序如下：</p>
<div class="highlight-container" data-rel="Cpp"><figure class="iseeu highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">void</span> __global__ <span class="title">find_neighbor_no_atomic</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="type">int</span> *d_NN, <span class="type">int</span> *d_NL, <span class="type">const</span> real *d_x, <span class="type">const</span> real *d_y, <span class="type">const</span> <span class="type">int</span> N, <span class="type">const</span> real cutoff_square</span></span></span><br><span class="line"><span class="params"><span class="function">)</span> </span>{</span><br><span class="line">    <span class="type">const</span> <span class="type">int</span> n1 = blockIdx.x * blockDim.x + threadIdx.x;</span><br><span class="line">    <span class="keyword">if</span> (n1 &lt; N) {</span><br><span class="line">        <span class="type">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="type">const</span> real x1 = d_x[n1];</span><br><span class="line">        <span class="type">const</span> real y1 = d_y[n1];</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> n2 = <span class="number">0</span>; n2 &lt; N; ++n2) {</span><br><span class="line">            <span class="type">const</span> real x12 = d_x[n2] - x1;</span><br><span class="line">            <span class="type">const</span> real y12 = d_y[n2] - y1;</span><br><span class="line">            <span class="type">const</span> real distance_square = x12 * x12 + y12 * y12;</span><br><span class="line">            <span class="keyword">if</span> ((distance_square &lt; cutoff_square) &amp;&amp; (n2 != n1)) {</span><br><span class="line">                d_NL[(count++) * N + n1] = n2;</span><br><span class="line">            }</span><br><span class="line">        }</span><br><span class="line">        d_NN[n1] = count;</span><br><span class="line">    }</span><br><span class="line">}  </span><br></pre></td></tr></table></figure></div>

<ul>
<li>这里改变了邻居列表的数据排列方式，将<code>d_NL[n1 * MN + count++]</code>改成了<code>d_NL[(count++) * N + n1]</code>。这是因为<code>n1</code>的变化步调与<code>threadIdx.x</code>一致，这样修改后，对全局内存数组<code>d_NL</code>的访问是合并的。</li>
</ul>
<p>以上源代码见 <a class="link" target="_blank" rel="noopener" href="https://github.com/fengyiqi/cppCUDA/blob/master/tutorials/neighborGPU.cu">neighborGPU.cu <i class="fa-regular fa-arrow-up-right-from-square fa-sm"></i></a>。经本人机器测试，使用原子函数大概耗时1.68ms，不使用原子函数大概耗时1.91ms（均为单精度）。</p>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>总的来说，使用原子函数的核函数性能较高。即使使用原子函数能够提升核函数的性能，它还是有一个缺点，即运用原子函数时会引入随机性，因为原子函数只能保证每个原子操作的完整性，并不能保证不同的原子操作之间具有特定的次序。</p>

            </div>

            

            
                <ul class="post-tags-box">
                    
                        <li class="tag-item">
                            <a href="/tags/CUDA/">#CUDA</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/C/">#C</a>&nbsp;
                        </li>
                    
                        <li class="tag-item">
                            <a href="/tags/C/">#C++</a>&nbsp;
                        </li>
                    
                </ul>
            

            

            
                <div class="article-nav">
                    
                        <div class="article-prev">
                            <a class="prev"
                            rel="prev"
                            href="/2023/cuda4/"
                            >
                                <span class="left arrow-icon flex-center">
                                    <i class="fa-solid fa-chevron-left"></i>
                                </span>
                                <span class="title flex-center">
                                    <span class="post-nav-title-item">CUDA编程04: 线程束基本函数与协作组</span>
                                    <span class="post-nav-item">上一篇</span>
                                </span>
                            </a>
                        </div>
                    
                    
                        <div class="article-next">
                            <a class="next"
                            rel="next"
                            href="/2023/mpi1/"
                            >
                                <span class="title flex-center">
                                    <span class="post-nav-title-item">MPI并行计算01: 几个最常用的函数</span>
                                    <span class="post-nav-item">下一篇</span>
                                </span>
                                <span class="right arrow-icon flex-center">
                                    <i class="fa-solid fa-chevron-right"></i>
                                </span>
                            </a>
                        </div>
                    
                </div>
            


            
        </div>

        
            <div class="toc-content-container">
                <div class="post-toc-wrap">
    <div class="post-toc">
        <div class="toc-title">此页目录</div>
        <div class="page-title">CUDA编程03: 全局内存、共享内存以及原子函数的合理使用</div>
        <ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%A8%E5%B1%80%E5%86%85%E5%AD%98%E7%9A%84%E5%90%88%E7%90%86%E4%BD%BF%E7%94%A8"><span class="nav-text">全局内存的合理使用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%A8%E5%B1%80%E5%86%85%E5%AD%98%E7%9A%84%E5%90%88%E5%B9%B6%E4%B8%8E%E9%9D%9E%E5%90%88%E5%B9%B6%E8%AE%BF%E9%97%AE"><span class="nav-text">全局内存的合并与非合并访问</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BE%8B%E5%AD%90%EF%BC%9A%E7%9F%A9%E9%98%B5%E8%BD%AC%E7%BD%AE"><span class="nav-text">例子：矩阵转置</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E7%9A%84%E5%90%88%E7%90%86%E4%BD%BF%E7%94%A8"><span class="nav-text">共享内存的合理使用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BE%8B%E5%AD%90%EF%BC%9A%E6%95%B0%E7%BB%84%E5%BD%92%E7%BA%A6%E8%AE%A1%E7%AE%97"><span class="nav-text">例子：数组归约计算</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8E%9F%E5%AD%90%E5%87%BD%E6%95%B0%E7%9A%84%E5%90%88%E7%90%86%E4%BD%BF%E7%94%A8"><span class="nav-text">原子函数的合理使用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%9F%E5%AD%90%E5%87%BD%E6%95%B0"><span class="nav-text">原子函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BE%8B%E5%AD%90%EF%BC%9A%E9%82%BB%E5%B1%85%E5%88%97%E8%A1%A8%E7%9A%84%E5%BB%BA%E7%AB%8B"><span class="nav-text">例子：邻居列表的建立</span></a></li></ol></li></ol>

    </div>
</div>
            </div>
        
    </div>
</div>


                

            </div>
            
            

        </div>

        <div class="main-content-footer">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info">
            &copy;
            
              <span>2022</span>
              -
            
            2023&nbsp;&nbsp;<i class="fa-solid fa-cog fa-spin" style="--fa-animation-duration: 15s;"></i>&nbsp;&nbsp;<a href="/">YiQi</a>
        </div>
        
            <script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv" class="busuanzi_container_site_uv">
                        访问人数&nbsp;<span id="busuanzi_value_site_uv" class="busuanzi_value_site_uv"></span>
                    </span>
                
                
                    <span id="busuanzi_container_site_pv" class="busuanzi_container_site_pv">
                        总访问量&nbsp;<span id="busuanzi_value_site_pv" class="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="theme-info info-item">
            <span class="powered-by-container">由 <?xml version="1.0" encoding="utf-8"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg version="1.1" id="圖層_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" width="1rem" height="1rem" viewBox="0 0 512 512" enable-background="new 0 0 512 512" xml:space="preserve"><path fill="#0E83CD" d="M256.4,25.8l-200,115.5L56,371.5l199.6,114.7l200-115.5l0.4-230.2L256.4,25.8z M349,354.6l-18.4,10.7l-18.6-11V275H200v79.6l-18.4,10.7l-18.6-11v-197l18.5-10.6l18.5,10.8V237h112v-79.6l18.5-10.6l18.5,10.8V354.6z"/></svg><a target="_blank" href="https://hexo.io">Hexo</a> 驱动</span>
                <br>
            <span class="theme-version-container">主题&nbsp;<a class="theme-version" target="_blank" href="https://github.com/EvanNotFound/hexo-theme-redefine">Redefine v2.1.4</a>
        </div>
        
        
        
            <div id="start_div" style="display:none">
                2022/12/21 11:45:14
            </div>
            <div>
                博客已运行 <span class="odometer" id="runtime_days" ></span> 天 <span class="odometer" id="runtime_hours"></span> 小时 <span class="odometer" id="runtime_minutes"></span> 分钟 <span class="odometer" id="runtime_seconds"></span> 秒
            </div>
        
        
        
            <script async data-pjax>
                try {
                    function odometer_init() {
                    const elements = document.querySelectorAll('.odometer');
                    elements.forEach(el => {
                        new Odometer({
                            el,
                            format: '( ddd).dd',
                            duration: 200
                        });
                    });
                    }
                    odometer_init();
                } catch (error) {}
            </script>
        
        
        
    </div>  
</footer>
        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="article-tools-list">
        <!-- TOC aside toggle -->
        
            <li class="right-bottom-tools page-aside-toggle">
                <i class="fa-regular fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
    </ul>
</div>

        </div>
    

    <div class="right-side-tools-container">
        <div class="side-tools-container">
    <ul class="hidden-tools-list">
        <li class="right-bottom-tools tool-font-adjust-plus flex-center">
            <i class="fa-regular fa-magnifying-glass-plus"></i>
        </li>

        <li class="right-bottom-tools tool-font-adjust-minus flex-center">
            <i class="fa-regular fa-magnifying-glass-minus"></i>
        </li>

        <li class="right-bottom-tools tool-expand-width flex-center">
            <i class="fa-regular fa-expand"></i>
        </li>

        <li class="right-bottom-tools tool-dark-light-toggle flex-center">
            <i class="fa-regular fa-moon"></i>
        </li>

        <!-- rss -->
        

        

        <li class="right-bottom-tools tool-scroll-to-bottom flex-center">
            <i class="fa-regular fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="visible-tools-list">
        <li class="right-bottom-tools toggle-tools-list flex-center">
            <i class="fa-regular fa-cog fa-spin"></i>
        </li>
        
            <li class="right-bottom-tools tool-scroll-to-top flex-center">
                <i class="arrow-up fas fa-arrow-up"></i>
                <span class="percent"></span>
            </li>
        
        
    </ul>
</div>

    </div>

    <div class="image-viewer-container">
    <img src="">
</div>


    


</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/layouts/navbarShrink.js"></script>

<script src="/js/tools/scrollTopBottom.js"></script>

<script src="/js/tools/lightDarkSwitch.js"></script>





    
<script src="/js/tools/codeBlock.js"></script>






    
<script src="/js/tools/runtime.js"></script>

    
<script src="/js/layouts/odometer.min.js"></script>

    
<link rel="stylesheet" href="/assets/odometer-theme-minimal.css">




  
<script src="/js/libs/Typed.min.js"></script>

  
<script src="/js/plugins/typed.js"></script>







<div class="post-scripts pjax">
    
        
<script src="/js/tools/tocToggle.js"></script>

<script src="/js/libs/anime.min.js"></script>

<script src="/js/layouts/toc.js"></script>

<script src="/js/plugins/tabs.js"></script>

    
</div>


    
<script src="/js/libs/pjax.min.js"></script>

<script>
    window.addEventListener('DOMContentLoaded', () => {
        window.pjax = new Pjax({
            selectors: [
                'head title',
                '.page-container',
                '.pjax',
            ],
            history: true,
            debug: false,
            cacheBust: false,
            timeout: 0,
            analytics: false,
            currentUrlFullReload: false,
            scrollRestoration: false,
            // scrollTo: true,
        });

        document.addEventListener('pjax:send', () => {
            Global.utils.pjaxProgressBarStart();
        });

        document.addEventListener('pjax:complete', () => {
            Global.utils.pjaxProgressBarEnd();
            window.pjax.executeScripts(document.querySelectorAll('script[data-pjax], .pjax script'));
            Global.refresh();
        });
    });
</script>




</body>
</html>
